[{"title":"MacOS系统自带简体拼音输入法Tips","date":"2017-08-24T06:20:31.000Z","path":"2017/08/24/Common/mac_pinyin_input_method/","text":"Mac上的简体中文拼音输入法主要有搜狗、鼠须管、系统自带输入法这几种。本文将介绍MacOS系统自带的简体拼音输入法的一些使用技巧。 参考链接 Mac OS X 自带拼音输入法小技巧 Mac 自带输入法这么好用，不看不知道 | 有用功 Mac 里的文字输入效率 候选词切换 －+或者←→，在单页候选词中切换，一个个切换 ［ ］或者↑↓，在多页候选词中切换，一页页切换 中英文数字混合输入 短按Caps lock切换中／英文输入法 长按Caps lock锁定／解锁大小写输入状态 Shift键用来输入大写 拼音输入法状态下，Return直接输入字母，空格则输入当前高亮的候选词 输入文字时，按住Shift就能输入大写字母，按住Option能输入数字 简体中文输入 &#39; 符号作为拼音之间的分隔符，例如：bei&#39;jing 北京 u 可以打开笔画输入框 Tab 可以在 1234 声调中切换选择 Shift+空格键就能输入可组合的汉字，如 jiji后按组合键即可输入喆 Option+Shift+L即可打开输入码搜索框 Control+Shift+空格键即可打开手写输入窗口（前提是有选择手写输入法） Command+Control+空格键，即可看到表情符号窗口 Option+Shift+B」或者「Shift+6，即可看到颜文字窗口 Control+Command+Shift+C转为繁体 Control+Option+Command+Shift+C转为简体 Delete 删除光标前内容 Fn+Delete 删除光标后内容 Shift+Delete 删除错误的个人候选词 输入特殊字符按住「Option」 +其他按键输入特殊字符 按住「Option」+ 「Shift」+ 其他按键输入特殊字符 快捷键总结按键标志符 标志符 对应按键 ⌃ Control ⌥ Option ⌘ Command ⇧ Shift ␣ 空格 ⇪ Caps Lock ⌫ Delete 快捷键 功能 标志符 快捷键 切换输入法 ⌃ ␣ Control+空格 手写输入法 ⌃⇧ ␣ Control+⇧+空格 切换中／英文输入法 ⇪ Caps Lock 候选词切换 +-←→ －+或者←→ 候选词页切换 []↑↓ ［ ］或者↑↓ 表情与符号 ⌃ ⌘ ␣ Control+Command+空格 颜文字与符号 ⌥ ⇧ B Option+Shift+B 颜文字与符号 ⇧ 6 Shift+6 听写 Fn Fn Fn+Fn 查找输入码 ⌥ ⇧ L Option+Shift+L 拆字输入 ⇧ ␣ Shift+空格 中文输入过程中输入大写字母 ⇧ Shift 中文输入过程中输入数字 ⌥ Option 转为繁体 ⌃ ⌘⇧ C Control+Command+Shift+C 转为简体 ⌃ ⌥ ⌘ ⇧ C Control+Option+Command+Shift+C 音调切换 Tab Tab 笔画输入 u u 拼音之间的分隔符 ‘ ‘ 删除光标前内容 ⌫ Delete 删除光标后内容 Fn ⌫ Fn+Delete 删除错误的个人候选词 ⇧ ⌫ Shift+Delete Alfred中设置输入法在Alfred的Preferences中的Advanced页中设置Force Keyboard为英文","tags":[{"name":"Mac","slug":"Mac","permalink":"https://blog.ajavac.com/tags/Mac/"}]},{"title":"Java 7 新特性","date":"2017-08-15T07:39:45.000Z","path":"2017/08/15/Java/java7/","text":"Oracle 公司于 2011 年 7 月 7 日发布 Java 7，添加了许多新特性 序号 特性 说明 1 switch中添加对字符串的支持 开关语句支持字符串 2 try-with-resource 自动化资源管理 3 钻石符号&lt;&gt; 类型自动推导 4 多异常捕捉 一次性捕捉多种异常 5 访问文件系统 新的文件访问方式 6 异步I/O 7 二进制常量以及下划线支持 switch中添加对字符串的支持123456789101112public static void main(String[] args)&#123; String aStr = \"string\"; switch (aStr) &#123; case \"1\": break; case \"2\": break; default: System.out.println(aStr); break; &#125;&#125; try-with-resource12345try ( InputStream is = new FileInputStream(\"a.txt\"); OutputStream os = new FileOutputStream(\"b.txt\")) &#123; char charStr = (char) is.read(); os.write(charStr);&#125; 只要操作类实现了AutoCloseable接口就可以在try语句块退出时自动调用close方法来关闭资源流 关闭方法的异常也可以直接catch 可以声明多个资源 钻石符号12// 钻石符号自动判断类型List&lt;String&gt; strList = new ArrayList&lt;&gt;(); 多异常捕捉123456try &#123; Thread.sleep(20000); FileInputStream fis = new FileInputStream(\"/a/b.txt\");&#125; catch (InterruptedException | IOException e) &#123; e.printStackTrace();&#125; 使用|可以声明同时对多类异常进行捕捉 访问文件系统Path 表示文件路径和文件 12Path path = Paths.get(\"/home/\", \"a.txt\");File file = path.toFile(); Files 快速操作文件 123456789101112131415// 读取文件内容byte[] data = Files.readAllBytes(Paths.get(\"a.txt\"));String content = new String(data, StandardCharsets.UTF_8);// 按行读取文件List&lt;String&gt; lines = Files.readAllLines(Paths.get(\"a.txt\"));// 写入文件Files.write(Paths.get(\"b.txt\"), \"Hello World\".getBytes());// 创建文件夹，若父文件夹不存在则自动创建Files.createDirectories(Paths.get(\"abc\",\"cda\",\"a.txt\"));// 拷贝文件Files.copy(Paths.get(\"a.txt\"),Paths.get(\"b.txt\")); ###","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"Docker Registry （Docker仓库）","date":"2017-08-07T07:00:06.000Z","path":"2017/08/07/Docker/docker_registry/","text":"简介 registry 是存放和分发Docker镜像的一个服务 Docker hub 可以类比为 Github，是一个公共的镜像服务中心 搭建 Registry 可以类比为搭建 GitLab 服务器，是一个私有的镜像服务中心 自建 Registry 可以让镜像私有化，也可以提高镜像拉取速度 运行RegistryOfficical docker run -d -p 5000:5000 --restart always --name registry registry 使用Registry123456789101112# 本地运行registrydocker run -d -p 5000:5000 --restart always --name registry registry# 从官方拉取镜像docker pull nginx:alpine# 给镜像加标签docker tag nginx:alpine localhost:5000/nginx:alpine# 推送镜像到本地registrydocker push localhost:5000/nginx:alpine# 删除本地镜像docker rmi nginx:alpine localhost:5000/nginx:alpine# 从本地registry 拉取镜像docker pull localhost:5000/nginx:alpine Registry API Registry 有一些API可以方便的看到Registry上都有哪些镜像 官方文档 API 示例 说明 /v2/ curl http://localhost:5000/v2/ 版本检查 /v2/_catalog curl http://localhost:5000/v2/_catalog 列出资源 /v2/&lt;name&gt;/tags/list curl http://localhost:5000/v2/mysql/tags/list 列出镜像标签 关于HTTPS问题 使用registry时，如果没有配置https会导致其他机器无法拉取镜像 错误提示： 1Error response from daemon: Get https://xx.xx.xx.xx:5000/v1/_ping: http: server gave HTTP response to HTTPS client 解决方法： 方法1: 配置HTTPS，参考官方文档 方法2: 在客户机配置该registry为非安全源 1234567# 编辑或者创建 daemon.json 配置文件vi /etc/docker/daemon.json# 添加或者输入如下内容&#123; \"insecure-registries\":[\"10.30.20.214:5000\"] &#125;# 重启 dockersudo service docker restart# 至此便可以正常拉取镜像了 定制可迁移的registry 若需要在一个内网环境部署docker，那么定制一个可迁移的registry会变使部署变得方便 1. 准备好一个registry容器123456789# 1. 运行registry容器docker run --name some_registry -d -p 5000:5000 --restart always registry# 2. 从docker hub拉取镜像,如nginx:alpinedocker pull nginx:alpine# 3. 标记该镜像docker tag nginx:alpine localhost:5000/nginx:alpine# 4. 推送该镜像到本地registrydocker push localhost:5000/nginx:alpine# 重复3和4的步骤，将需要的镜像都推送到本地registry 2. 导出旧registry的数据12# some_registry为旧registry容器名docker run --rm --volumes-from some_registry -v $(pwd):/backup registry sh -c \"cd /var/lib/ &amp;&amp; tar cvf /backup/backup.tar registry\" 3. 运行新registry容器12# 在目标机器运行新registry容器（注意端口占用）docker run --name new_registry -d -v /var/lib/registry -p 5000:5000 --restart always registry 4. 导入数据1234# 导入数据（注意backup.tar要在当前路径下）docker run --rm --volumes-from new_registry -v $(pwd):/backup registry sh -c \"cd /var/lib/ &amp;&amp; tar xvf /backup/backup.tar\"# 查看registry目录，检查是否导入数据成功curl localhost:5000/v2/_catalog","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ajavac.com/tags/Docker/"}]},{"title":"Nginx跨域","date":"2017-07-17T03:31:22.000Z","path":"2017/07/17/Nginx/nginx_cors/","text":"简介 跨域(CORS)全称是 (Cross-origin resource sharing), 由于浏览器的安全限制, 所以才会存在跨域问题 当一个网站的去请求另一个网站的资源时会发生 新版浏览器都支持该功能 (不低于IE10) 简单请求简介必须同时满足以下条件: 请求方法是以下三种方法之一: HEAD GET POST 头信息不超过以下字段: Accept Accept-Language Content-Language Last-Event-ID Content-Type: 只限(application/x-www-form-urlencoded、multipart/form-data、text/plain) 不满足条件的为非简单请求, 浏览器会直接发出CORS请求, 也就是在头信息中增加一个Origin字段 配置Nginx可以通过简单的配置实现简单请求的跨域 在http或者server或者location里面添加add_header &#39;Access-Control-Allow-Origin&#39; &#39;*&#39;;这行命令, 即允许任意Origin地址进行跨域请求 比如在http里面添加: 1234http &#123; add_header Access-Control-Allow-Origin *; # 以下省略 非简单请求简介不满足简单请求的皆为非简单请求: 比如请求方法是PUT或者DELETE 比如Content-Type是application/json 非简单请求在正式通信(简单请求)之前会进行一次预检请求(preflight) 预检请求是一个OPTIONS请求, 所以需要对该请求进行处理 配置在location里面对OPTIONS请求进行特殊配置 12345678910111213location / &#123; if ($request_method = &apos;OPTIONS&apos;) &#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access-Control-Allow-Methods&apos; &apos;*&apos;; # Custom headers and headers various add_header &apos;Access-Control-Allow-Headers&apos; &apos;Content-Type&apos;; # Tell client that this pre-flight info is valid for 20 days add_header &apos;Access-Control-Max-Age&apos; 1728000; add_header &apos;Content-Type&apos; &apos;text/plain charset=UTF-8&apos;; add_header &apos;Content-Length&apos; 0; return 204; &#125; # 以下省略 参考跨域资源共享 CORS 详解","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.ajavac.com/tags/Nginx/"}]},{"title":"Java 集合框架","date":"2017-06-28T09:50:51.000Z","path":"2017/06/28/Java/java_collection/","text":"集合 Java集合框架是指导Java的集合类。Collection 接口是一组允许重复的对象。Set 接口继承 Collection，但不允许重复，使用自己内部的一个排列机制。 List 接口继承 Collection，允许重复，以元素安插的次序来放置元素，不会重新排列。Map接口是一组成对的键－值对象，即所持有的是key-value pairs。Map中不能有重复的key。拥有自己的内部排列机制。 —— wiki Collection 接口继承了 Iterable 接口 List Queue Set 接口继承了 Collection 接口 List List 接口继承了 Collection 接口 表示一个有序集合(有序序列), 所有元素通过插入产生, 可以通过数字索引查找 允许重复元素 Vector List的一种基于可变数组的实现 允许所有的元素, 包括null 与ArrayList大致相同, 除了它是同步的, 在单线程环境下优先使用ArrayList 特点是: 线程安全(同步), 查找速度快(可按索引), 添加和删除速度较慢( 相对LinkedList ) 当capacity(容量) 不足时候自动进行扩容, 为原来2倍(可定制) 通过预先确定容量可以节省扩容消耗的时间 fail-fast机制避免遍历时列表被修改(会抛出异常ConcurrentModificationException) 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug 遍历优先使用forEach方法 当需要在遍历时候添加或者删除元素时, 使用ListIterator ArrayList List的一种基于可变数组的实现 允许所有的元素, 包括null 与Vector大致相同, 除了它是非同步的 特点是: 非线程安全(非同步), 查找速度快(可按索引), 添加和删除速度较慢( 相对LinkedList ) 当capacity(容量) 不足时候自动进行扩容, 为原来1.5倍 通过预先确定容量可以节省扩容消耗的时间 fail-fast机制避免遍历时列表被修改(会抛出异常ConcurrentModificationException) 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug 遍历优先使用forEach方法 当需要在遍历时候添加或者删除元素时, 使用ListIterator LinkedList List 的一种基于双向链表的实现 允许所有的元素, 包括null 特点是: 非线程安全(非同步), 查找速度慢(需要遍历), 添加和删除速度快(相对ArrayList不需要数组拷贝) fail-fast机制避免遍历时列表被修改(会抛出异常ConcurrentModificationException) 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug 遍历优先使用forEach方法 当需要在遍历时候添加或者删除元素时, 使用ListIterator Queue Queue 接口继承了 Collection 接口 表示一个有优先级的队列 部分队列有容量的限制, 大部分则没有限制(即插入操作不会失败) 一般队列是FIFO (first-in-first-out)方式的 优先队列(PriorityQueue) 通过比较来排列元素顺序 没有定义非阻塞队列方法, 非阻塞队列接口为 BlockingQueue 通常不允许添加null元素, LinkedList允许, 但最好不要, 因为null常常用来作为特殊的返回值 队列的实现类通常没有实现基于元素的equals和hashCode方法, 因为即使队列元素相同, 队列顺序也常常不同 功能 抛出异常 返回特殊值(如null或者false) 添加元素 add(e) offer(e) 获取并删除队列头部元素 remove() poll() 获取队列头部元素 element() peek() LinkedList Dqueue (双端队列)/Queue(队列)的一种基于双向链表的实现 也可以用作栈, 即 LIFO (last-in-first-out) 允许所有的元素, 包括null, 但是不建议 特点是: 非线程安全(非同步), 可充当队列或者栈, 无容量限制 PriorityQueue 继承自AbstractQueue, 是优先级队列的一种实现 (小顶堆) 不允许null元素 无外部容量限制, 内部容量限制为数组最大容量 特点是: 非线程安全(非同步), 可自定义优先级(比较规则) 容量不足时自动扩容, 若原容量小于64则扩容为原来2倍加2, 否则扩容为原来1.5倍 Set Set 接口继承了 Collection 接口 存储一组不重复的元素, 他们之间都是不相等的(通过equals方法判断) 最多存储一个null元素 虽然没有禁止, 但是如果保存可变元素, 可能会破坏Set的不重复特性 一般来说, 禁止保存自身作为元素 Set接口的实现类可以选择对元素进行限制 HashSet 基于HashMap实现 允许null元素 无序, 非同步 LinkedHashSet 基于LinkedHashMap实现, 继承了HashSet 允许null元素 有序, 非同步 相同元素重复插入时, 顺序不变 TreeSet 通常情况下基于TreeMap实现, 实现了NavigableSet接口 不允许null元素 有序, 非同步 相同元素重复插入时, 顺序不变 Map 一种用户保存键值对映射的数据结构 不可保存重复的键值 每个键可以映射最多一个值 取代了类Dictionary 提供了三种视图(view): 键视图/值视图/键值对视图 警惕可变类作为map的键的情况, 可能导致键值对不可达 一般不允许自引用 Hashtable 继承了Dictionary&lt;K,V&gt;, 实现了Map&lt;K,V&gt; 非null的对象可以作为键或者值 线程安全, 有序 键必须要实现hashCode和equals方法 initial capacity(初始容量) 和 load factor(负载因子, 默认0.75) 影响其性能 扩容时是原来的两倍+1 fail-fast机制避免了在iterator(遍历)过程中对Hashtable进行操作, 若发生操作则抛出ConcurrentModificationException异常 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug Hashtable是同步的, 现在版本已不推荐使用. 需要线程安全可以使用ConcurrentHashMap, 不需要线程安全可以使用HashMap HashMap 继承了AbstractMap&lt;K,V&gt;, 实现了Map&lt;K,V&gt; 允许null作为键或者值 非线程安全, 无序 除了允许null和非同步外和Hashtable比较类似 initial capacity(初始容量, 默认16) 和 load factor(负载因子, 默认0.75) 影响其性能 扩容时是原来的两倍 fail-fast机制避免了在iterator(遍历)过程中对HashMap进行操作, 若发生操作则抛出ConcurrentModificationException异常 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug LinkedHashMap 继承了HashMap&lt;K,V&gt;, 实现了Map&lt;K,V&gt; 允许null作为键或者值 非线程安全, 有序 它比HashMap多记录了插入键值对的顺序(使用双向链表, 可以改为访问顺序), 重复插入同个键不影响顺序 initial capacity(初始容量, 默认16) 和 load factor(负载因子, 默认0.75) 影响其性能 扩容时是原来的两倍 fail-fast机制避免了在iterator(遍历)过程中对LinkedHashMap进行操作, 若发生操作则抛出ConcurrentModificationException异常 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug 因为维持了双向链表, 所以遍历性能比HashMap高 TreeMap 继承了AbstractMap&lt;K,V&gt;, 实现了NavigableMap&lt;K,V&gt; 基于红黑树实现，通过键的比较方法（compareTo）或者比较器（Comparator）进行排序，开销是log(n) 不允许null作为键或者值 非线程安全, 有序 插入后不应该再修改该键 fail-fast机制避免了在iterator(遍历)过程中对TreeMap进行操作, 若发生操作则抛出ConcurrentModificationException异常 不能过分依赖fail-fast机制, 只能充当一份基本的保障, 用来查找bug Utils JDK 提供了一些工具类用来方便地操作集合和数组 Arrays 包含许多操作数组的静态方法 sort 方法用来对数组进行排序 parallelSort 方法用来对数组进行并行排序 binarySearch 方法用来二分查找数组中的元素 equals 用来比较两个数组的内容 fill 用来往数组中填充内容 copyOf 用来复制数组 asList 用来将数组转化成ArrayList hashCode 用来计算数组的hash值 toString 用来将数组转化成字符串 Collections 包含许多操作集合的静态方法 sort 方法用来对List进行排序 binarySearch 方法用来对List进行二分查找 reverse 方法用来对List进行顺序反转操作 shuffle 方法用来对List进行随机排列 swap 方法用来交换List中两个元素 fill 方法用来对List进行填充 copy 方法用来拷贝List min 方法用来获取集合中的最小值 max 方法用来获取集合中的最大值 replaceAll 方法用来对List中的某一值进行替换 unmodifiableList 方法用来包装List以获得一个不可变的List synchronizedList 方法用来包装List以获得一个线程安全的List emptyList 方法用来获得一个不可变的空List singletonList 方法用来获得一个单值的List 参考 Java 集合框架 — Wiki","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Collection","slug":"Collection","permalink":"https://blog.ajavac.com/tags/Collection/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"Linux 网卡配置","date":"2017-06-25T13:15:02.000Z","path":"2017/06/25/Linux/linux_network/","text":"一般情况查看网卡信息ip add 或者 ifconfig 重启网络sudo service network restart ubuntu修改配置sudo vi /etc/network/interfaces 1234567auto enp0s3iface enp0s3 inet staticaddress 192.168.56.5network 192.168.56.0netmask 255.255.255.0gateway 192.168.56.1dns-nameservers 8.8.8.8 192.168.56.1 重启网络配置sudo service networking restart 查看网卡信息ip add 或者 ifconfig 安装sshsudo apt-get install openssh-server 检查是否启动ps -e|grep ssh centos修改配置sudo vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 创建或修改配置文件信息如下（根据你实际的环境进行修改）： 12345BOOTPROTO=staticONBOOT=yesIPADDR=192.168.56.10NETMASK=255.255.255.0GATEWAY=192.168.56.1 #双网卡下删除此项,避免覆盖","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.ajavac.com/tags/Linux/"},{"name":"Config","slug":"Config","permalink":"https://blog.ajavac.com/tags/Config/"}]},{"title":"Linux常用命令","date":"2017-06-25T13:11:20.000Z","path":"2017/06/25/Linux/linux_command/","text":"开发过程中可能用到的一些命令 netstat 查看网络信息 netstat -an | grep 80808080替换成需要查看的端口号 lsof 查看网络信息 lsof -i:80-i参数表示网络链接，:80指明端口号，该命令会同时列出PID，方便kill lscpu 查看cpu信息 类似效果 cat /proc/cpuinfo free 查看内存信息 free -m free -h 类似效果 cat /proc/meminfo dmidecode -t memory lsblk 查看磁盘信息 类似效果 fdisk -l ifconfig 查看网卡信息 ifconfig -a 类似效果 lspci | grep -i &#39;eth&#39; ip add ip link show ethtool eth0 lspci 查看硬件信息 lscpi -t lspci -v 或者 lspci -vv 类似效果 dmidecode -q","tags":[{"name":"Terminal","slug":"Terminal","permalink":"https://blog.ajavac.com/tags/Terminal/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.ajavac.com/tags/Linux/"}]},{"title":"Java IO","date":"2017-06-20T01:15:39.000Z","path":"2017/06/20/Java/java_io/","text":"BIO 面向流, 阻塞IO 字节流InputStream 方法 说明 read() 一次读取一个字节(0-255), 当读取到文件末尾时返回-1 read(byte[]) 一次性读取一个字节数组, 返回读取到的字节数, 当读取到末尾时返回-1 OutputStream 方法 说明 write(int) 写入一个字节(0-255)的数据 write(byet[]) 写入一个字节数组 字符流InputStreamReader 方法 说明 read() 一次读取一个字符(int), 当读取到文件末尾时返回-1 read(char[]) 一次性读取一个字符数组, 返回读取到的字符数, 当读取到末尾时返回-1 OutputStreamReader 方法 说明 write(int) 写入一个字符的数据 write(char[]) 写入一个字符数组 try-with-resource Java 7 开始引入, 替代传统用finally关闭流的方式 1234567891011public static void main(String[] args)&#123; try(InputStream input = new FileInputStream(\"file.txt\")) &#123; int data = input.read(); while(data != -1)&#123; System.out.println((char) data); data = input.read(); &#125; &#125; catch(IOException e) &#123; throw UncheckedIOException(e); &#125;&#125; 在try块结束后, 自动完成流的关闭操作, 大大简化的流操作的编程 不用进行finally块的流关闭操作以及关闭操作的异常处理, 直接在catch块对异常进行统一处理) 可以使用多个资源, 关闭时按顺序进行关闭 可以自定义类, 只要实现了 AutoClosable 即可 当关闭流异常时, 直接由catch块捕捉 当try块和关闭流都抛出异常时, 抛出try块的异常, 关闭流的异常被抑制, 情况正好与finally方式相反 ​ NIO 面向缓冲, 非阻塞IO, 三大组件 通道 (Channel) 既可以从通道中读取数据, 又可以写数据到通道 可读可写 可以异步 总是先读取到一个Buffer, 或者从一个Buffer中写入 通道实现 说明 FileChannel 从文件中读写数据 DatagramChannel 能通过UDP读写网络中的数据 SocketChannel 能通过TCP读写网络中的数据 ServerSocketChannel 可以监听新进来的TCP连接, 对每个新进来的连接都会创建一个SocketChannel 缓冲区 (Buffer) 用于和NIO通道进行交互, 本质是一块可以写入数据, 然后可以从中读取数据的内存 用法: 写入数据到Buffer 调用flip()方法 从Buffer中读取数据 调用clear()方法或者compact()方法 选择器 (Selector) 选择器允许一个单独的线程来监视多个通道 I/O模型I/O类型 同步(Sync)/异步(Async) 阻塞(Block)/非阻塞(Unblock) 主要针对Client端: 同步: 一个功能调用,在没有得到结果前,该调用不返回.期间不能干其他事 异步: 一个功能调用后,调用者不能立刻得到结果.实际处理调用的部件在完成后,通过状态/通知和回调来通知调用者.举例:Ajax请求 主要针对Server端: 阻塞: 调用结果返回之前,当前线程被挂起(线程暂停运行,不同于同步). 非阻塞: 与阻塞概念对立,不能立刻得到结果时,该函数不会阻塞当前线程,而会立刻返回. 阻塞对象上可以有非阻塞的调用方式,非阻塞对象上可以有阻塞的调用方式. 同/异步由Client端控制,但是需要Server端配合实现,Client端不关心Server端是否阻塞/非阻塞 同/异步区别: 数据访问的时候进程是否阻塞 阻塞/非阻塞区别: 应用程序的调用是否立即返回 Linux 下的五种I/O模型 阻塞I/O（blocking I/O） 非阻塞I/O （nonblocking I/O） I/O复用(select 和poll) （I/O multiplexing） 信号驱动I/O （signal driven I/O (SIGIO)） 异步I/O （asynchronous I/O (the POSIX aio_functions)） 前4种都是同步IO,第5种才是异步IO NIO给我们带来了些什么： 事件驱动模型 避免多线程 单线程处理多任务 非阻塞I/O，I/O读写不再阻塞，而是返回0 基于block的传输，通常比基于流的传输更高效 更高级的IO函数，zero-copy IO多路复用大大提高了Java网络应用的可伸缩性和实用性","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"JVM","date":"2017-06-14T09:41:03.000Z","path":"2017/06/14/Java/jvm/","text":"主要讨论 HotSpot 虚拟机 Java平台体系 图片来源: Java Platform Standard Edition 8 Documentation JVM五大区 JVM运行时数据区(Runtime Data Area) 可能抛出异常 线程私有 程序计数器(Program Counter Register) 无 是 虚拟机栈(VM Stack) StackOverflowError/OutOfMemoryError 是 本地方法栈(Native Method Stack) StackOverflowError/OutOfMemoryError 是 堆(Heap) OutOfMemoryError 否 方法区(Method Area) OutOfMemoryError 否 程序计数器 程序计数器(Program Counter Register)是一块较小的内存空间,可以看作当前线程所执行的字节码的行号指示器 字节码解释器工作时通过改变程序计数器的值来选取下一条需要执行的字节码指令 分支/循环/跳转/异常处理/线程恢复等基础功能都需要依赖程序计数器来完成 每条线程的程序计数器互补影响,独立存储 执行Java方法时,程序计数器记录的是正在执行的虚拟机字节码指令的地址 执行Native方法时,程序计数器的值为空(Undefined) 程序计数器是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域 Java虚拟机栈 Java虚拟机栈(Java Virtual Machine Stacks) 也是线程私有的, 它的生命周期与线程相同 虚拟机栈描述的是Java方法执行的内存模型 每个Java方法在执行时都会创建一个栈帧(Stack Frame)用于存储局部变量表/操作数栈/动态链接/方法出口等信息 每个Java方法从调用到执行完成的过程,对应一个栈帧在虚拟机栈中入栈到出栈的过程 64位长度的long和double类型的数据会占用2个局部变量空间(Slot),其余的数据类型只占用1个 局部变量表所需的内存空间在编译期间完成分配,当进入一个方法时,这个方法所需在帧中分配多大的局部变量空间是完全确定的,在方法运行期间不会改变局部变量表的大小 若线程请求的栈深度大于虚拟机锁允许的深度, 将抛出StackOverflowError异常 若虚拟机可以动态扩展(大部分Java虚拟机都支持)且扩展时无法申请到足够的内存, 将抛出OutOfMemoryError异常 局部变量表存放的各种基本数据类型: 局部变量表基本数据类型 默认值 占用空间bit boolean false 1 byte 0x00 16 char ux0000 16 short 0 8 int 0 32 float 0.0 32 long 0 64 double 0.0 64 reference null 32/64 对象引用(reference类型), 不等同于对象本身,可能是指向对象起始地址的引用指针,也可能是指向一个代表对象的句柄或其他与此对象相关的位置 returnAddress类型指向了一条字节码指令的地址 本地方法栈 本地方法栈(Native Method Stack)与虚拟机栈的作用非常相识, 只不过是虚拟机栈为Java方法服务, 而本地方法栈为虚拟机使用到的Native方法服务 若线程请求的栈深度大于虚拟机锁允许的深度, 将抛出StackOverflowError异常 若虚拟机可以动态扩展(大部分Java虚拟机都支持)且扩展时无法申请到足够的内存, 将抛出OutOfMemoryError异常 Java堆 一般情况下Java堆(Java Heap) 是Java虚拟机所管理的内存中最大的一块 Java 堆是被所有线程共享的一块内存区域, 在虚拟机启动时创建 唯一目的是存放对象实例, 几乎所有对象实现都在这里分配内存 Java 堆是垃圾收集器管理的主要区域,所以也成为GC堆(Garbage Collected Heap) 根据垃圾收集器的分代收集算法, Java堆还可以细分为: 新生代和老年代等 Java 堆可以处于物理上不连续的内存空间中, 只要逻辑上是连续的即可 可以通过-Xmx和-Xms控制Java 堆的大小 当Java 堆中没有内存完成实例分配, 并且堆也无法再扩展时, 将会抛出OutOfMemoryError异常 方法区 方法区(Method Area) 与Java 堆一样, 是各个线程共享的内存区域, 用于存储已被虚拟机加载的类信息/常量/静态变量/即使编译器(JITC)编译后的代码等数据 别名为Non-Heap(非堆), 目的在于和Java 堆区分开来 常被称为永久代(Permanent Generation), 本质上两者并不等价 当方法区无法满足内存分配需求时, 将抛出OutOfMemoryError异常 运行时常量池 运行时常量池(Runtime Constant Pool)是方法区的一部分 用于存放编译器生成的各种字面量和符合引用, 将在类加载后进入方法区的运行时常量池中存放 具备动态性, 比如String的intern()方法 当常量池无法再申请到内存时会抛出OutOfMemoryError异常 直接内存 直接内存(Direct Memory) 不是虚拟机运行时数据区的一部分,但是也能导致OutOfMemoryError异常出现 JDK 1.4 中新加入 NIO 类,引入了基于通道(Channel)和缓冲区(Buffer)的I/O方式,它可以使用Native函数库直接分配堆外内存,然后通过操作存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作 避免了在Java堆和Native堆来回复制数据,显著提高性能 不受Java堆大小限制,受本机总内存(RAM和SWAP或者分页文件)大小和处理器寻址空间的限制 通过-Xmx配置虚拟机参数时要注意直接内存并不受这个参数限制,需要考虑内存区域总和是否大于物理内存限制 可能抛出OutOfMemoryError异常 垃圾收集器 垃圾收集 (Garbage Collection, GC) 需要解决3件事情: 那些内存需要回收(What)/什么时候回收(When)/如何回收(How) 对象存活判断 常见判断方法有引用计数算法和可达性分析算法 引用计数算法 给对象添加引用计数器, 当有一个地方引用它时就加1, 当引用失效时就减1, 引用计数器为0的对象就是不可能再被使用的 实现简单, 判定效率高 应用案例有: 微软的COM技术/FlashPlayer/Python/Squirrel等 主流Java虚拟机并没有选用引用计数算法来管理内存, 因为其难以解决对象之间相互循环引用问题 可达性分析算法 主流的商用程序语言(Java/C#/Lisp)就是使用可达性分析算法 (Reachability Analysis)来判定对象是否存活 通过一系列称之为GC Roots的对象作为起始点, 从这些节点开始向下搜索, 搜索锁走过的路径称为引用链 (Reference Chain), 当一个对象到GC Roots没有任何引用链相连(即GC Roots到这个对象不可达),则此对象是不可用的 在Java中, 可作为GC Roots的对象有: 虚拟机栈 (栈帧中的本地变量表) 中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI (Native方法) 引用的对象 引用类型 Java 对引用的概念进行了扩充, 分为4种引用类型 强引用 (Strong Reference): 即代码中普遍存在的引用, 只要引用还存在, 垃圾收集器永远不会回收掉被引用的对象, 如String str = &quot;I am OK&quot;; 软引用 (Soft Reference): 用来描述一些还有用但并非必需的对象, 在系统将要发生内存溢出异常之前, 将会对这些对象列入回收范围之中进行第二次回收,若回收后内存还是不足, 才会抛出内存溢出溢出. 在 JDK 1.2 之后, 提供了SoftReference 类来实现软引用 弱引用 (weak Reference): 弱引用也是用来描述非必需对象的, 但是它比软引用更弱一些, 被弱引用关联的对象只能生存到下一次垃圾收集发生之前, 无论当前内存是否足够. 在 JDK 1.2 之后, 提供了WeakReference 类来实现弱引用 虚引用 (Phantom Reference): 也称幽灵引用或者幻影引用, 它是最弱的一种引用关系. 一个对象是否有虚引用存在, 完全不会对其生存时间构成影响, 也无法通过虚引用来取得一个对象实例. 为一个对象设置虚引用的唯一目的是能在这个对象被收集器回收时收到一个系统通知. 在 JDK 1.2 之后, 提供了PhantomReference 类来实现虚引用 对象回收 在可达性分析算法中不可达的对象, 也并非一定会被回收, 至少要经历两次标记过程 如果对象进行可达性分析后发现没有与 GC Roots 相连接的引用链, 那他将会被第一次标记并且进行一次筛选, 筛选条件是该对象是否有必要执行finalize()方法 当对象没有覆盖 finalize()方法或者finalize()方法已经被虚拟机调用过, 虚拟机将这两种情况都视为 “没必要执行” 若对象被判定为有必要执行 finalize() 方法, 那么该对象将会被放置在一个叫做 F-Queue 的队列中, 并在稍后由一个虚拟机自动建立的、低优先级的Finalizer 线程去执行它, 但是并不承诺会等待它运行结束 (避免该方法长久占用执行资源, 导致其他队列中的对象永久等待, 甚至导致整个内存回收系统崩溃) finalize()方法是对象逃脱死亡命运的最后一次机会, 稍后 GC 将对 F-Queue 中的对象进行第二次小规模的标记, 检查其中对象是否有重新与 GC Roots 建立引用链 finalize()方法运行代价高昂, 不建议使用它 回收方法区 永久代的垃圾收集主要回收 废弃常量 和 无用的类 回收废弃常量与回收Java堆中的对象非常类似 类需要同时满足3个条件才能算作无用的类,才可以被回收: 该类所有实例都已经被回收(即 Java 堆中不存在该类的任何实例) / 加载该类的 ClassLoader 已经被回收 / 该类对应的 java.lang.Class 对象没有在任何地方被引用, 无法在任何地方通过反射访问该类的方法 Hotspot 虚拟机可以通过 -Xnoclassgc 控制是否对类进行回收 Hotspot 虚拟机可以通过 -verbose:class 以及 -XX:+TraceClassLoading 和 -XX:TraceClassUnLoading 查看类加载和卸载信息 在大量使用反射/动态代理/CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁定义ClassLoader的场景都需要虚拟机具备类卸载功能， 以保证永久代不会溢出 垃圾收集算法 常见的垃圾收集(GC)算法有: 标记-清除算法/复制算法/标记-整理算法/分代收集算法 标记-清除算法 标记-清除 (Mark-Sweep) 算法是最基础的收集算法, 后续的算法都是基于这种思路并对其不足进行改进而得到的 算法分为标记和清除两个阶段,首先标记出要回收的对象, 在标记完成后统一回收所有被标记的对象 不足一, 效率问题, 标记和清除这两个过程效率都不高. 不足二, 空间问题, 标记清除之后会产生大量不连续的内存碎片, 导致下次分配大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作 复制算法 复制(Copying) 算法, 将可用内存按容量划分为大小相等的两块, 每次只用其中一块 当使用的那一快内存用完了, 就将存活着的对象复制到另一块上面, 然后将已使用过的内存空间一次清理掉 内存分配时不用考虑内存空间碎片等复杂情况, 实现简单, 运行高效 不足一, 将内存缩小为原来的一半 不足二, 在对象存活率较高时就要进行较多的复制操作, 效率将会变低, 所以老年代一般不直接使用这种算法 现在的商业虚拟机都采用这种收集算法来回收新生代 (可能采用8:1:1的方式) 标记-整理算法 标记-整理(Mark-Compact) 算法, 标记过程和标记-清除算法一样, 但是后续步骤不是直接对可回收对象进行清理, 而是让所有存活对象都向一端移动, 然后直接清理掉端边界以外的内存 不足, 效率问题, 标记和整理这两个过程效率都不高 分代收集算法 分代收集(Generational Collection) 算法, 根据对象存活周期的不同将内存划分为几块 一般讲Java堆划分为新生代和老年代, 根据各个年代的特定采用最适当的收集算法. 新生代每次垃圾收集都有大批对象死去, 只有少量存活, 那就选用复制算法. 老年代对象存活率高, 没有额外空间对它进行分配担保, 使用标记-清除算法或者标记-整理算法 HotSpot 的算法实现 枚举根节点, 可达性分析会导致GC停顿(Stop the World), 使用称为OopMap的数据结构实现 安全点(Safep`oint), 使用主动式中断(Voluntary Suspension) , 不使用抢先式中断(Preemptive Suspension) 安全区域(Safe Region), 线程处于Sleep状态或者Blocked 状态时, 无法响应JVM的中断请求, 所以需要安全区域来解决这个问题, 所以JVM发起GC时就不用管标识自己为Safe Region 状态的线程了 常见的垃圾收集器 如果说垃圾收集算法是内存回收的方法论, 那么垃圾收集器就是内存回收的具体实现 对垃圾收集器来说的并行和并发 并行 (Parallel) : 多条垃圾收集器线程并行工作, 此时用户线程仍然处于等待状态 并发 (Concurrent): 用户线程和垃圾收集线程同时执行(不一定并行, 可能交替执行) Serial 收集器 新生代收集器, 是最基本/发展历史最悠久的收集器, 在JDK 1.3.1之前是新生代收集器的唯一选择 单线程, 一条收集线程, 而且收集时必须暂停其他所有的工作线程直到收集结束 是虚拟机运行在Client模式下的默认新生代收集器 优点: 简单/高效 缺点: 单线程收集/必须暂停其他所有工作线程 ParNew 收集器 新生代收集器, 是Serial 收集器的多线程版本 多线程, 多条收集线程, 而且收集时必须暂停其他所有的工作线程直到收集结束 是虚拟机运行在Server模式下的默认新生代收集器 只有它能与CMS收集器配合工作 在单CPU环境下绝不会有比Serial 收集器更好的效果 优点: 简单/高效/多线程 缺点: 必须暂停其他所有工作线程 Parallel Scavenge 收集器 新生代收集器, 使用复制算法的收集器, 并行的多线程收集器 目标是达到一个可控制的吞吐量 (Throughput) , 吞吐量= 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间) 适合用在后台运算而不需要太多交互的任务, 比如服务器 优点: 吞吐量可控/多线程 缺点: 不适合对响应速度要求高的地方/必须暂停其他所有工作线程 Serial Old 收集器 老年代收集器, 单线程收集器, 使用标记-整理算法 主要给Client模式下的虚拟机使用 Server模式下, 用途: 一在JDK 1.5及以前版本中与Parallel Scavenge 收集器搭配使用, 二作为CMS收集器的后备方案, 在并发收集发生 Concurrent Mode Failure时使用 优点: 简单/高效 缺点: 单线程收集/必须暂停其他所有工作线程 Parallel Old 收集器 老年代收集器, 使用多线程和标记-整理算法, 是Parallel Scavenge 收集器的老年代版本 JDK 1.6及之后版本才提供 在注重吞吐量以及CPU资源敏感的场合(如服务器), 优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器的组合 优点: 吞吐量优先/多线程 缺点: 必须暂停其他所有工作线程 CMS 收集器 老年代收集器, CMS (Concurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器, 基于标记-清除算法实现的 B/S 架构的服务器尤其重视服务的响应速度, 希望系统停顿时间最短, 以给用户带来较好的体验 过程: 初始标记 (CMS initial mark, 会Stop the World), 并发标记(CMS concurrent mark), 重新标记(CMS remark, 会Stop the World), 并发清除(CMS concurrent sweep) 优点: 并发收集/低停顿 (Concurrent Low Pause Collector) 缺点: 对CPU资源非常敏感 /无法处理浮动垃圾(Floating Garbage) /清理后会有大量空间碎片产生 G1 收集器 新生代/老年代收集器, G1(Garbage First) 是当今收集器技术发展的最前沿成果之一, 在 JDK 1.7 后提供 G1 是一款面向服务端应用的垃圾收集器, 可以独立管理整个GC堆 特点: 并行与并发/分代收集/空间整合/ 优点: 停顿时间短且可预测/收集效果好/不会产生空间碎片 缺点: 不够成熟 MinorGC 指发生在新生代中的垃圾收集动作, 采用复制算法, 也称新生代GC 一般回收速度比较快, 次数也非常频繁 大对象直接进入老年代, 避免短命大对象 长期存活对象进入老年代, 动态对象年龄判断, 空间分配担保 触发条件: 只要Eden空间不足就开始进行 新生代按8:1:1的比例分为三个区: Eden/from/to -XX:+PrintGCDetails 可以打印内存回收日志 FullGC / Major GC 针对整个新生代/老生代/元空间的全局范围的GC, 老年代采用标记-清除算法, 也称老年代GC 经常会伴随至少一次的 Minor GC (并非绝对) 一般比Minor GC 慢10倍以上 触发条件: 老年代空间不足/ PermSpace (元空间) 不足 / 统计得到的Minor GC 晋升到老年代的平均大小大于老年代的剩余空间 JVM监控和优化 监控数据: 运行日志/异常堆栈/GC日志/线程快照(threaddump / javacore 文件)/堆转储快照( heapdump / hprof 文件) 等 命令行工具 名称 主要作用 jps JVM Process Status Tool, 显示指定系统内所有的 HotSpot 虚拟机进程 jstat JVM Statistics Monitoring Toll, 用于收集 HotSpot 虚拟机各方面的运行数据 jinfo Configuration Info for Java, 显示虚拟机配置信息 jmap Memory Map for Java, 生成虚拟机的内存转储快照 (heapdump 文件) jhat JVM Heap Dump Browser, 用于分析heapdump 文件, 会建立 HTTP 服务器, 可在浏览器中查看分析结果 jstack Stack Trace for Java, 显示虚拟机的线程快照 可视化工具 名称 作用 jconsole JConsole (Java Monitoring and Management Console) Java 监视与管理控制台, 是一种基于 JMX 的可视化监视/管理工具 jvisualvm JVisual (All-in-One Java Trobleshooting Tool)多合一运行监控和故障处理工具 日志查询-XX:+PrintGCDetails 可以打印内存回收日志 参数设置 参数 说明 -Xms20M 限制Java堆的初始大小/最小大小为20M -Xmx30M 限制Java堆的最大大小为30M -Xmn10M 限制Java堆的新生代大小为10M -XX:SurvivorRatio=8 新生代中Eden区与一个Survivor区的空间比例是8:1 JVM 类加载 类从被加载到虚拟机内存中开始, 到卸载出内存位置, 它的整个生命周期包括: 加载(Loading) 、验证 (Verification) 、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)、卸载(Unloading). 其中验证、准备、解析3个部分统称为连接(Linking) 类加载过程加载 通过一个类的全限定名来获取定义此类的二进制流, 来源可以是: class文件/zip包/网络/运行时计算生成(动态代理)/由其他文件生成(JSP)/从数据库中读取 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象,作为方法区这个类的各种数据的访问入口 加载阶段和连接阶段的部分内容是交叉进行的, 但是两个阶段的开始时间仍然保持固定的先后顺序 验证 确保Class文件的字节流中包含的信息符合当前虚拟机的要求, 并且不会危害虚拟机自身的安全 大致分为4个阶段的检验动作: 文件格式验证(文件格式规范)/ 元数据验证(语义分析,数据类型分析)/ 字节码验证(数据流/控制流分析,方法体校验分析)/ 符号引用验证(访问性分析) 准备 正式为类变量(static 变量)分配内存, 并设置类变量初始值, 在方法区中分配 通常情况下初始值是零值, 除非是final类型常量 解析 将常量池内的符号引用替换为直接引用 初始化 真正开始执行类中定义的Java 程序代码(字节码) 父类初始化方法先执行完毕, 再开始执行子类的初始化方法 同一个类加载器下, 一个类型只会初始化一次 双亲委派模型 从Java 虚拟机角度, 只有两种不同的类加载器: 启动类加载器(Bootstrap ClassLoader)和其他类加载器(Other ClassLoader) 从Java开发人员角度, 类加载器有三类: 启动类加载器(Bootstrap ClassLoader) / 扩展类加载器(Extension ClassLoader) / 应用程序类加载器(Application ClassLoader) 类加载器的关系模型一般为双亲委派模型 (Parents Delegation Model) 除了顶层的启动类加载器外, 其余的加载器都应有自己的父类加载器 类加载器之间的关系一般是组合(Composition)而不是继承(Inheritance) 工作过程: 如果一个类加载器收到了类加载请求, 它首先不会自己去尝试加载这个类, 而是把这个请求委派给父类加载器去完成, 每一层加载器都是如此, 只有当父加载器反馈自己无法完成(它的搜索范围内未找到所需的类)这个加载请求时, 子加载器才会尝试自己去加载 保证Java程序的稳定运行, 避免重复加载 参考 《深入理解Java虚拟机》","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"Docker之清理","date":"2017-05-31T08:45:53.000Z","path":"2017/05/31/Docker/docker_cleanup/","text":"容器12345678# 清理退出的容器docker rm $(docker ps -q -f status=exited)# 杀死所有正在运行的容器docker kill $(docker ps -a -q)# 删除所有已经停止的容器docker rm $(docker ps -a -q) 镜像12345678# 清理虚悬镜像docker rmi $(docker images -q -f \"dangling=true\")# 删除所有虚悬镜像docker rmi $(docker images -q -f dangling=true)# 删除所有镜像docker rmi $(docker images -q) 数据卷1234# 列出虚悬数据卷docker volume ls -qf dangling=true# 删除虚悬数据卷docker volume rm $(docker volume ls -qf dangling=true)","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ajavac.com/tags/Docker/"}]},{"title":"利用Docker搭建开发环境","date":"2017-05-31T08:40:53.000Z","path":"2017/05/31/Docker/docker_dev/","text":"安装DockerDocker官网 MySQL 官方Repository 运行docker run --name some-mysql -p 3306:3306 -v ~/my_data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=admin -d mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 说明： some-mysql 是自定义的容器名称 -p 3306:3306 是端口映射配置 ~/my_data/mysql 代表存储mysql的配置以及数据的目录 连接测试docker run -it --link some-mysql:mysql --rm mysql sh -c &#39;exec mysql -h&quot;$MYSQL_PORT_3306_TCP_ADDR&quot; -P&quot;$MYSQL_PORT_3306_TCP_PORT&quot; -uroot -p&quot;$MYSQL_ENV_MYSQL_ROOT_PASSWORD&quot;&#39; Redis 官方Repository 运行docker run --name some-redis -d -p 6379:6379 redis:alpine redis-server 说明： some-redis 是自定义的容器名称 -p 6379:6379 是端口映射配置 连接测试docker run -it --link some-redis:redis --rm redis:alpine redis-cli -h redis -p 6379 Mongo 官方Repository 运行docker run --name some-mongo -v ~/my_data/mongo:/data/db -d -p 27017:27017 mongo 说明： some-mongo 是自定义的容器名称 -p 27017:27017 是端口映射配置 ~/my_data/mongo 代表存储mongo的配置以及数据的目录 连接测试docker run -it --link some-mongo:mongo --rm mongo sh -c &#39;exec mongo &quot;$MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_PORT/test&quot;&#39; Nginx 官方Repository 运行docker run --name some-nginx -v ~/my_data/nginx:/usr/share/nginx/html:ro -d -p 8080:80 nginx:alpine 说明： some-nginx 是自定义的容器名称 -p 8080:80 是端口映射配置 ~/my_data/nginx 代表存储nginx静态文件的目录 Java 官方Repository Node 官方Repository","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ajavac.com/tags/Docker/"}]},{"title":"Docker之容器","date":"2017-05-31T08:35:53.000Z","path":"2017/05/31/Docker/docker_container/","text":"启动新建并启动12345# -t 分配伪终端并绑定到容器标准输出 -i 让容器标准输入打开# docker run 创建容器sudo docker run -t -i ubuntu:14.04 /bin/bashpwdls 若本地不存在镜像会自动下载 利用镜像创建并启动容器 分配一个文件系统,并在只读镜像层外挂载一层读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动已终止的容器docker start &lt;容器标识&gt; 守护态运行通常通过参数-d实现 要获取容器的输出信息，可以通过 docker logs 命令 终止 docker stop &lt;容器标识&gt;来终止守护态运行中的容器 exit或Ctrl+d来退出终端容器 终止状态的容器可以用 docker ps -a 命令看到 处于终止状态的容器，可以通过 docker start &lt;容器标识&gt; 命令来重新启动 docker restart &lt;容器标识&gt; 命令会将一个运行态的容器终止，然后再重新启动它 ​ 进入容器进入守护态运行中的容器 attach命令docker attach &lt;容器标识&gt; 当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示 nsenter命令方法步骤 导出和导入导出容器docker export 7691a814370e &gt; ubuntu.tar 导入容器cat ubuntu.tar | sudo docker import - test/ubuntu:v1.0 删除 删除终止状态容器docker rm &lt;容器标识&gt; 强制删除运行中的容器docker rm -f &lt;容器标识&gt; 清理所有处于终止状态的容器docker rm $(docker ps -a -q)","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ajavac.com/tags/Docker/"}]},{"title":"Docker之镜像","date":"2017-05-31T08:30:53.000Z","path":"2017/05/31/Docker/docker_image/","text":"获取镜像123456#从官方Docker Hub获取ubuntu:14.04docker pull ubuntu:14.04#运行docker run -it --rm ubuntu:14.04 bashcat /etc/os-releaseexit docker run: 就是运行容器的命令 -it：这是两个参数， -i交互式操作， -t 终端 —rm：这个参数是说容器退出后随之将其删除 ubuntu:14.04：这是指用 ubuntu:14.04 镜像为基础来启动容器 bash：放在镜像名后的是命令 cat /etc/os-release:这是 Linux 常用的查看当前系统版本的命令 exit :退出了这个容器 列出镜像123456789101112131415161718#列出当前镜像docker images#仓库名和标签都为&lt;none&gt;的是虚悬镜像,列出虚悬镜像docker images -f dangling=true#删除虚悬镜像docker rmi $(docker images -q -f dangling=true)#列出所有镜像,可能包括库名和标签都为&lt;none&gt;的中间层镜像docker images -a#列出部分镜像,比如ubuntudocker images ubuntu#过滤镜像docker images -f since=mongo:3.2docker images -f before=mongo:3.2docker images -f label=com.example.version=0.1#以特定格式列出镜像docker images -qdocker images --format \"&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;\"docker images --format \"table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;\" commit1234567891011121314151617181920#运行一个镜像docker run --name webserver -d -p 80:80 nginx#进入容器命令行交互界面,并做修改docker exec -it webserver bashecho '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.htmlexit#查看修改docker diff webserver#将容器保存为镜像docker commit \\ --author \"test &lt;test@gmail.com&gt;\" \\ --message \"修改了默认网页\" \\ webserver \\ nginx:v2#查看镜像docker images nginx#查看镜像内的历史记录docker history nginx:v2#运行新的镜像docker run --name web2 -d -p 81:80 nginx:v2 慎用 docker commit 若清理不当会导致镜像臃肿 操作为黑箱操作，生成的是黑箱镜像 每次commit都在当前层操作，可能导致镜像臃肿 一般在学习和被入侵后保存现场时用 定制镜像用Dockerfile Dockerfile Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 基本指令12345678910111213141516171819# FROM 指定基础镜像必须放在第一个,其中scratch为是一个空镜像FROM nginx# RUN 就像直接在命令行中输入的命令一样 # shell 格式：RUN &lt;命令&gt;# exec 格式：RUN [\"可执行文件\", \"参数1\", \"参数2\"]RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html# 使用 &amp;&amp; 将各个所需命令串联起来。简化为 1 层,并进行了清理操作RUN buildDeps='gcc libc6-dev make' \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ &amp;&amp; wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\" \\ &amp;&amp; mkdir -p /usr/src/redis \\ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ &amp;&amp; make -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis install \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm redis.tar.gz \\ &amp;&amp; rm -r /usr/src/redis \\ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 构建镜像1234567891011# 方式1.在Dockerfile文件所在目录执行命令 格式如:docker build [选项] &lt;上下文路径/URL/-&gt; # 涉及了上下文的概念以及Docker的C/S设计docker build -t nginx:v3 .# 方式2.直接用 Git repo 进行构建docker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14# 方式3.用给定的 tar 压缩包构建docker build http://server/context.tar.gz# 方式4.从标准输入中读取 Dockerfile 进行构建,它没有上下文,所以不能copy本地文件docker build - &lt; Dockerfile # 或者cat Dockerfile | docker build -#方式5.从标准输入中读取上下文压缩包进行构建,并将压缩包内容作为上下文docker build - &lt; context.tar.gz Dockerfile指令COPY 复制文件 COPY package.json /usr/src/app/ 从上下文目录中复制,可以是通配符 目标路径可以是容器内的绝对路径，也可以是相对于工作目录的相对路径，不存在会自动生成 源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。 ADD 更高级的复制文件 ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz / 若源文件为压缩文件，将会自动解压缩这个压缩文件到目标路径去 所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD CMD 容器启动命令 CMD echo $HOME 相当于 CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 容器中的应用都应该以前台执行，容器内没有后台服务的概念 CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 以前台形式运行nginx ENTRYPOINT 入口点 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数 当指定了 ENTRYPOINT 后，CMD不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，实际执行时&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 通过 docker run 的参数 —entrypoint 可以指定别的入口点 可以让镜像变成像命令一样使用，docker run可以直接加上参数运行 应用运行前的准备工作，启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作 ENV 设置环境变量 通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。 12345# 方式1ENV VERSION 1.0# 方式2ENV VERSION=1.0 DEBUG=on \\ NAME=\"Happy Feet\" 可以使用$VERSION这种形式来获取环境变量值 ARG 构建参数12345# 方式1ARG VERSION 1.0# 方式2ARG VERSION=1.0 DEBUG=on \\ NAME=\"Happy Feet\" 效果同ENV 但是只在构建时有效 docker history 可以看到所有值 docker build 中可以用 --build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖 VOLUME 定义匿名卷 VOLUME /data 或者 VOLUME [&quot;/data&quot;,&quot;/test&quot;] 挂在卷用以保存动态数据 运行时可以覆盖这个挂载设置docker run -d -v mydata:/data xxxx EXPOSE 声明端口 EXPOSE 8080或者EXPOSE [&quot;80&quot;,&quot;8080&quot;] 仅仅是声明运行时容器提供服务端口，并不会自动在宿主进行端口映射 docker run -P 时，会自动随机映射 EXPOSE 的端口 WORKDIR 指定工作目录 WORKDIR /app 指定工作目录（或者称为当前目录），改变环境状态并影响以后的层 该目录需要已经存在，WORKDIR 并不会建立目录 如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令 USER 指定当前用户 USER redis 指定当前用户，改变环境状态并影响以后的层 用户必须是事先建立好的，否则无法切换 HEALTHCHECK 健康检查 Docker 1.12 后引入 HEALTHCHECK 支持下列选项： --interval=&lt;间隔&gt;：两次健康检查的间隔，默认为 30 秒； --timeout=&lt;时长&gt;：健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒； --retries=&lt;次数&gt;：当连续失败指定次数后，则将容器状态视为 unhealthy，默认 3 次。 命令的返回值决定了该次健康检查的成功与否：0：成功；1：失败； 12345# 如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK NONE#每 5 秒检查一次，如果健康检查命令超过 3 秒没响应就视为失败，并且使用 curl -fs http://localhost/ || exit 1 作为健康检查命令。HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1 ONBUILD 为他人做嫁衣裳 ONBUILD &lt;其它指令&gt; 只有当以当前镜像为基础镜像，去构建下一级镜像的时候才会被执行 其他方式从rootfs压缩包导入格式:docker import [选项] &lt;文件&gt;|&lt;URL&gt;|- [&lt;仓库名&gt;[:&lt;标签&gt;]] 1234#创建一个OpenVZ的ubuntu14.04的镜像docker import \\ http://download.openvz.org/template/precreated/ubuntu-14.04-x86_64-minimal.tar.gz \\ openvz/ubuntu:14.04 docker save和docker load12345678# 保存镜像docker save alpine | gzip &gt; alpine-latest.tar.gz# 导入镜像docker load -i alpine-latest.tar.gz# 从一个机器将镜像迁移到另一个机器，并且带进度条的功能docker save &lt;镜像名&gt; | bzip2 | pv | ssh &lt;用户名&gt;@&lt;主机名&gt; 'cat | docker load' 删除本地镜像格式:docker rmi [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 参考Docker — 从入门到实践","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ajavac.com/tags/Docker/"}]},{"title":"初识Docker","date":"2017-05-31T08:27:53.000Z","path":"2017/05/31/Docker/docker_info/","text":"docker 是什么？ Docker是一个开放源代码软件项目，让应用程序布署在软件容器下的工作可以自动化进行，借此在Linux操作系统上，提供一个额外的软件抽象层，以及操作系统层虚拟化的自动管理机制。Docker利用Linux核心中的资源分离机制，例如cgroups，以及Linux核心命名空间（name space），来建立独立的软件容器（containers）。这可以在单一Linux实体下运作，避免启动一个虚拟机器造成的额外负担。 ——摘自维基百科 虚拟机: Docker: ——图片来自www.docker.com docker 跟原有的工具有何区别？ 实现更轻量级的虚拟化，方便快速部署 docker技术使软件交付标准化 像集装箱一样生成镜像，使得开发环境与生产环境一致 docker的出现使得[一次构建，到处部署]成为了可能 统一的管理服务 持续交付应用 快速(秒级)启动 传统的部署模式是：安装(包管理工具或者源码包编译)-&gt;配置-&gt;运行； Docker的部署模式是：复制-&gt;运行。 docker 会对服务器端开发/部署带来什么变化？ 对开发的影响不大 对于部署来说，是场革命。极大的减少部署的时间成本和人力成本 诱人之处 资源独立/隔离 环境一致性 轻量化 Build Once, Run Everywhere Linux系统要求 64位操作系统 Linux内核大于等于3.10 推荐操作系统(全部为64位Linux操作系统): Ubuntu 16.10 Ubuntu 16.04 Ubuntu 14.04 RHEL 7 CentOS 7 Fedora 24 Fedora 25 Debian 7.7 Debian 8.0 文章docker八个应用场景","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.ajavac.com/tags/Docker/"}]},{"title":"Linux 基础","date":"2017-04-10T01:19:17.000Z","path":"2017/04/10/Linux/linux_basic/","text":"包管理器apt-get apt-get 是Debian/Ubuntu等Debian系列系统自带的包管理工具 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 命令:update - 检索 新的包列表upgrade - 升级 可更新的所有软件包install - 安装 新软件包（pkg是libc6不是libc6.deb）remove - 删除 软件包autoremove - 自动删除 所有未使用的软件包purge - 删除 软件包和配置文件clean - 清除 已下载的归档文件autoclean - 清除 旧的下载的档案文件check - 验证 是否有损坏的依赖download - 下载 二进制包到当前目录 # 选项：-q ：不输出任何信息-qq ：除了错误之外，没有输出-d ：仅下载，不要安装或解压缩存档-y ：对所有确定询问都选择 Yes，并且不提示-f ：尝试纠正 被破坏依赖关系的系统-m ：如果存档是可定位的，则尝试继续-u ：显示升级包的列表-b ：在获取源代码包后构建源包 # 更多的命令可以用 apt-get --help 查看。# 示例# 检索 新的包列表apt-get update # 升级 可更新的所有软件包（注意这个命令会升级所有的软件包，所以会升级很长时间）apt-get upgrade # 安装 Nginx 软件包apt-get install nginx # 卸载 Nginx 软件包apt-get remove nginx # 卸载 Nginx 软件包 并删除所有相关配置文件apt-get remove --purge nginx # 在安装软件和卸载的时候，为了避免误操作，都会询问是否继续，每次都要输入 y 来确定会很麻烦，可以加上 -y 参数# 安装 Nginx 软件包 并不显示确定提示apt-get install nginx -y # 卸载 Nginx 软件包，删除所有相关配置文件 并不显示提示apt-get remove --purge nginx -y # 清除 旧的/无用 的软件包apt-get clean &amp;&amp; apt-get autoclean # 下载 Nginx 二进制软件包到当前目录，但不解压和安装apt-get download nginx -d yum yum 是 CentOS等REHAL系列系统自带的包管理工具 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# 命令： update - 检索 新的包列表upgrade - 升级 软件包search - 搜索 软件包install - 安装 软件包list - 列出 软件包或者软件包组info - 显示软件包或者软件包组的详细信息erase - 删除 软件包（这两个命令一样）remove - 删除 软件包（这两个命令一样）groupinfo - 显示 有关包组的详细信息groupinstall - 安装 软件包组（就像一种软件合集）grouplist - 列出 可用的软件包组groupremove - 删除 软件包组check - 检查 软件包check-update - 检查 可更新的软件包clean - 清除 缓存目录内的软件包deplist - 列出 一个包的依赖关系distribution-synchronization - 同步 已安装的软件包到最新的版本downgrad - 降级 一个软件包reinstall - 重新安装 软件包（自动删除重装）repolist - 显示 配置的软件包仓库resolvedep - 确定 软件包需要的依赖关系 # 选项：-t ：容忍错误-C ：完全从系统缓存运行，不要更新缓存-R 分钟 ：最大命令等待时间-q ：安静的操作-y ：对于所有问题回答是--nogpgcheck ：禁用gpg签名检查 # 更多的命令可以用 yum --help 查看。# 示例# 检索 新的包列表yum update # 安装 Nginx 软件包yum install nginx # 安装 Development Tools 软件包组（这个软件包组中包含了编译所需的软件）# 注意：当软件包或者软件包组的名字中包含空格的时候，请把 软件包或软件包组 加上双引号！yum groupinstall \"Development Tools\" # 卸载 Nginx 软件包yum erase nginx / yum remove nginx # 卸载 Development Tools 软件包组yum groupremove \"Development Tools\" # 升级 所有可更新的软件包yum upgrade # 升级 Nginx 可更新的软件包yum upgrade nginx # 在安装软件和卸载的时候，为了避免误操作，都会询问是否继续，每次都要输入 y 来确定会很麻烦，可以加上 -y 参数# 安装 Nginx 软件包 并不显示确定提示yum install nginx -y # 卸载 Nginx 软件包 并不显示确定提示yum erase nginx -y / yum remove nginx -y # 搜索 Nginx 软件包是否存着yum search nginx # 列出 可用的软件包yum list # 列出 可用的软件包组yum grouplist # 清除 缓存目录中的所有软件包yum clean # 清除 缓存目录中的 Nginx 软件包yum clean nginx # 重装 Nginx 软件包yum reinstall nginx 文件/文件夹默认以当前目录/root为例 mkdir 新建 文件夹123# 在当前文件夹新建一个 bash 文件夹，完整的绝对路径就是 /root/bashmkdir bash# 更多的命令可以用 mkdir --help 查看。 cd 进入文件夹123456789# 你当前在 /root目录中，使用这个命令会进入 /root/bash目录，这是相对路径cd bash# 如果你不在 /root目录中的话，就不能用上面的相对路径了，就需要绝对路径cd /root/bash# 假设你当前在 /root/bash目录中，使用相对路径，你可以用这个命令进入上一级 /root目录， .. 代表相对路径 上级目录cd ..# 当然你也可以用绝对路径来进入上一级 /root目录cd /root cp 复制或重命名 文件/文件夹123456789101112131415161718192021222324252627282930# 复制当前目录内的 log.txt文件到 /var目录cp log.txt /var/log.txt# 复制当前目录内的 bash文件夹到 /home目录cp -R bash /home/bash# 复制当前目录内的所有.txt后缀的文件到 /var/log目录cp *.txt /var/log# 复制当前目录内的所有以 doubi开头的文件到 /var/log目录cp doubi* /var/log# 复制当前目录内的所有以 doubi开头 以.txt后缀结尾的文件到 /var/log目录cp doubi*.txt /var/log# 假设当前目录是 /root/doubi/log，要把这个目录中的所有.txt后缀的文件复制到上一级目录 /root/doubi，那么这样做cp *.txt ..# .. 就是相对路径，代表上一级目录，当然你也可以用绝对路径，这样更不容易出错cp *.txt /root/doubi# 重命名当前目录内的 log.txt文件为 log2.txtcp log.txt log2.txt# 复制当前目录内的 log.txt文件到 /var目录并重命名为 log1.txtcp log.txt /var/log1.txt# 复制当前目录内的 bash文件夹到 /home目录并重命名为 bash2cp -R bash /home/bash2# 复制当前目录内的 log.txt文件到 /var目录，但是 /var 目录中已经存着 log.txt，那么会提示 cp: overwrite `/var/log.txt'? 可以用 -f 强制覆盖cp -f log /var/log.txt# 复制当前目录内的 log.txt log1.txt log2.txt文件和 log233目录到 /home/log目录中cp -R log.txt log1.txt log2.txt log233 /home/log # 更多的命令可以用 cp --help 查看。 mv 移动或重命名 文件/文件夹123456789101112131415# 关于 mv 命令，可以参考上面 cp 的使用方法，没什么区别，只是一个是复制，一个是移动，把上面 cp 命令改成 mv 就能套用了。 # 移动当前目录内的 log.txt文件到 /var目录mv log.txt /var/log.txt# 移动当前目录内的 bash文件夹到 /home目录mv bash /home/bash————————————————————————————————————————————————————————————————————————————# 重命名当前目录内的 log.txt文件为 log2.txtmv log.txt log2.txt# 复制当前目录内的 log.txt文件到 /var目录并重命名为 log1.txtmv log.txt /var/log1.txt# 复制当前目录内的 bash文件夹到 /home目录并重命名为 bash2mv bash /home/bash2 # 更多的命令可以用 mv --help 查看。 rm 删除 文件/文件夹12345678910111213141516171819202122232425# 删除当前目录下的 log.txt文件rm log.txt# 删除当前目录下所有.txt后缀的文件rm *.txt# 使用 rm 命令删除时，会提示你是否确定删除，输入 y 即删除，输入 n 则取消# rm: remove regular file `log.txt'? y————————————————————————————————————————————————————————————————————————————# 删除当前目录下所有.txt后缀的文件rm *.txt# 删除当前目录下所有以 doubi开头的文件rm doubi*# 删除当前目录下所有以 doubi开头 以.txt后缀结尾的文件rm doubi*.txt————————————————————————————————————————————————————————————————————————————# 当你用 rm 删除目录的时候会发现提示这不是一个文件# rm bash# rm: cannot remove `bash': Is a directory# 可以加上 -r 来归递删除目录及其目录下的内容rm -r bash————————————————————————————————————————————————————————————————————————————# 因为为了避免手误删除错误，所以 rm默认是加上了 -i 的参数，也就是每一次删除文件/目录都会提示，如果觉得烦可以用 -rf 参数rm -rf bash# rm -rf 这个命令请慎重使用，而且千万不要使用 rm -rf / 或者 rm -rf /* 之类的命令(系统自杀)，可能会让你系统爆炸，所以使用请慎重！ # 更多的命令可以用 rm --help 查看。 查看/编辑文件ls 显示目录中文件12345678910# 显示当前目录下的所有文件ls -a————————————————————————————————————————————————————————————————————————————# 命令后面加上 绝对路径/相对路径 就会显示指定文件夹内的所有文件ls -a bash/log# 相对路径，当前目录是 /root ，欲查看的目录是 /root/bash/logls -a /root/bash/log# 绝对路径， 当前目录是 /root ，欲查看的目录是 /root/bash/log # 更多的命令可以用 ls --help 来查看。 du 查看 文件/文件夹 占用磁盘空间的大小12345678910111213141516171819202122-h ：以人类易读的方式显示-a ：显示 目录占用的磁盘空间大小，并显示其下目录和文件占用磁盘空间的大小-s ：显示 目录占用的磁盘空间大小，但不显示其下子目录和文件占用的磁盘空间大小-c ：显示几个目录或文件占用的磁盘空间大小，还要统计它们的总和--apparent-size：显示目录或文件自身的大小-l ：统计硬链接占用磁盘空间的大小-L ：统计符号链接所指向的文件占用的磁盘空间大小# 待写... # 更多的命令可以用 du --help 来查看。# 示例# 显示 /root 文件夹的大小，但不显示其子目录和文件的大小du -sh # 显示 /root 文件夹的大小，并显示其子目录和文件的大小du -ah # 待写... # 更多的命令可以用 du --help 来查看。 cat 查看文件内容123456789101112131415161718192021222324252627282930# 查看 log.txt文件的所有内容cat log.txt# 查看 log.txt文件的所有内容，并对所有行编号cat -n log.txt# 查看 log.txt文件的所有内容，并对非空行编号cat -b log.txt# 查看 log.txt文件的所有内容，并对非空行编号，且不输出多行空行cat -bs log.txt# 清空当前目录中的 log.txt 文件cat /dev/null &gt; log.txt # 清空 /var目录中的 log.txt 文件cat /dev/null &gt; /var/log.txt# 写入文本到当前目录中的 log.txt文件中(加入文本到文件内容最后)cat &gt;&gt; log.txt &lt;&lt;-EOFdoubidoubi233doubi666EOF # 清空文件并写入文本到 /var目录中的 log.txt文件中(先清空后写入)cat &gt; /var/log.txt &lt;&lt;-EOFdoubidoubi233doubi666EOF # 更多的命令可以用 cat --help 来查看。 head 查看文件内容（主要用于正查）123456789101112131415161718192021222324252627-c 数字：显示指定文件的前 xx 字节的内容（bytes）-n 数字：显示指定文件的前 xx 行的内容-q ：不显示包含指定文件名的文件头（当使用 head打开多个文件的时候，会去在每个文件输出结果的顶部添加一个包含文件名的文件头用于区分） # 更多的命令可以用 head --help 来查看。# 示例# 查看 log.txt文件的全部内容head log.txt # 查看 log.txt文件的前 4字节的内容head -c 4 log.txt # 输出示例doub # 查看 log.txt文件的前 2行的内容head -n 2 log.txt # 输出示例doubi1doubi2 # 查看 log.txt log1.txt log2.txt文件的前 3行内容head -n 3 log.txt log1.txt log2.txt # 更多的命令可以用 head --help 来查看。 tail 查看文件内容（主要用于倒查）123456789101112131415161718192021222324252627282930313233343536373839404142434445-c 数字：如果数字为正数(例如 -c +5)，显示指定文件从行首第 xx 字节到最后的内容；如果数字为负数(例如 -c -5)，显示指定文件从行尾第 xx 字节到最后内容。-n 数字：如果数字为正数(例如 -c +3)，显示指定文件从行首第 xx 行到最后的内容；如果数字为负数(例如 -c -3)，显示指定文件从行尾第 xx 行到最后的内容。-f ：即时输出文件变化后增加的内容，也就是监视一个文件的内容变化（常用于监视日志输出），使用 Ctrl＋C 终止 # 更多的命令可以用 tail --help 来查看。# 示例# 查看 log.txt文件的全部内容tail log.txt # 查看 log.txt文件从行首 第25字节到最后的内容tail -c +25 log.txt # 输出示例bi4doubi5doubi6 # 查看 log.txt文件从行尾 第4字节到最后的内容tail -c -4 log.txt # 输出示例bi5 # 查看 log.txt文件的前 2行的内容tail -n +2 log.txt # 输出示例doubi1doubi2 # 查看 log.txt文件的后 2行的内容tail -n -2 log.txt # 输出示例doubi5doubi6 # 持续查看（监视） log.txt文件的变化内容（新增加的内容），使用 Ctrl＋C 终止tail -f log.txt # 查看 log.txt log1.txt log2.txt文件的前 3行内容tail -n 3 log.txt log1.txt log2.txt # 更多的命令可以用 tail --help 来查看。 sed 查看/编辑文件内容12345678910111213141516171819202122232425262728293031323334353637-i ：操作后应用保存到原文件（如果不加这个参数，那么任何修改都不会影响原文件里的内容，只会把结果输出）# 待写... # 更多的命令可以用 sed --help 来查看。# 示例# 查看 log.txt 第3行的内容sed '3p' log.txt # 查看 log.txt 第2-8行的内容sed '2,8p' log.txt # 删除 log.txt 第4行sed -i '4d' log.txt # 删除 log.txt 第3-7行sed -i '3,7d' log.txt # 删除 log.txt 第1行sed -i '1d' log.txt # 删除 log.txt 最后1行sed -i '$d' log.txt # 删除 log.txt 文件中所有包含 233内容的行sed -i '/233/d' log.txt # 替换 log.txt 文件中所有 233为666sed -i 's/233/666/' log.txt # 替换 log.txt 文件中所有 /ver 为 doubi/，因为有斜杠，所以需要使用 \\ 转义，但是单引号会导致无法转义，所以要改成双引号。sed -i \"s/\\/ver/doubi\\//\" log.txt # 待写... # 更多的命令可以用 sed --help 来查看。 vi、vim、nano 编辑文件内容 vi是Linux非常流行的文本编辑器，vim相当于vi的增强版，一般Linux操作系统会自带vi，而vim需要手动安装（yum install vim -y / apt-get install vim -y） vim1234567891011121314151617181920212223242526272829# 打开当前目录下的 log.txt文件，如果没有那么会新建 log.txt文件（安装vim后，使用 vi和 vim打开文件没区别）vi log.txtvim log.txt # 在命令行模式下，直接输入以下 符号和字母(区分大小写)## 进入编辑模式（插入模式，按 Esc键 即可返回命令行模式）i## 删除光标当前所在的一行dd## 删除文件内所有内容dddG## 复制光标当前所在的一行yy## 粘贴刚才复制的一行内容p## 撤销上个操作（误操作可以用这个恢复）u## 保存当前文件（ : 是英文的冒号）:w## 另存当前文件内容为 log2.txt:w log2.txt## 退出当前文件:q## 不保存 并强制退出当前文件:q!## 保存并退出当前文件:wq # 更多的命令可以用 vi --help / vim --help 来查看。 nano 一般系统也会默认安装的一个文本编辑器 12345678910# 打开当前目录下的 log.txt文件，如果没有那么会新建 log.txt文件nano log.txt# 进入后直接就可以输入修改文本内容了，修改后我们可以使用这个 按键保存内容Ctrl+O# 如果不需要编辑了，那么可以用这个 按键退出当前文件Ctrl+X# 如果你在退出前已经修改但没有保存，那么会提醒你是否保存，如果保存就输入 y ，不保存输入 n# 然后就会让你输入要保存的文件名（默认原文件名，所以直接按 Enter回车即可，除非你要另存为其他文件名）Enter# 更多的命令可以用 nano --help 来查看。 压缩文件操作 常见压缩文件格式有：zip、rar、gz、xz、tar.gz、tar.xz、tar.bz、tar.bz2等tar 本身只是一个打包的作用，.tar后面的才是压缩格式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495-x 是从压缩文件提取(解压)文件出来，所以在解压命令中都有这个参数。-c ：创建一个新的压缩包文件，所以在压缩命令中都有这个参数。-f ：指定要解压的压缩包文件或要压缩的文件/文件夹，所以这个参数必须放在 解压缩命令参数的最后，然后后面跟着 要解压到压缩包文件或要压缩的文件/文件夹。-j ：解压缩 bz / bz2 格式的参数-J ：解压缩 xz / lzip 格式的参数-z ：解压缩 gz / tgz 格式的参数-Z ：解压缩 Z 格式的参数-v ：详细列出解压缩过程中处理的文件 # 更多的命令可以用 tar --help 来查看。# tar gz zip等 解压 压缩包 示例# 解压后缀为 .tar 的压缩包tar -xf log.tar————————————————————————————————————————————————————————————————————————————# 解压后缀为 .tar.xz 的压缩包tar -xJf log.tar.xz————————————————————————————————————————————————————————————————————————————# 解压后缀为 .tar.gz 的压缩包，有两个方法tar -xzf log.tar.gz————————————————————————————————————————————————————————————————————————————# 解压后缀为 .gz 的压缩包，有两个方法，如提示命令不存在，请安装 yum install gzip -y / apt-get install gzip -ygzip -d log.gzgunzip log.gz————————————————————————————————————————————————————————————————————————————# 解压后缀为 .bz / .bz2 / tar.bz2 的压缩包，有两个方法bzip2 -d log.bzbunzip2 log.bztar -jxf log.tar.bz bzip2 -d log.bz2bunzip2 log.bz2tar -jxf log.tar.bz2————————————————————————————————————————————————————————————————————————————# 解压后缀为 .Z / tar.Z 的压缩包，有两个方法uncompress log.Z log.txtuncompress log.Z log————————————————————————————————————————————————————————————————————————————tar xZf log.tar.Z log.txttar xZf log.tar.Z log————————————————————————————————————————————————————————————————————————————# 解压后缀为 .rar 的压缩包，如提示命令不存在，请安装 yum install unrar -y / apt-get install unrar -y ，注意 rar 和 unrar 是分开的unrar x log.rar————————————————————————————————————————————————————————————————————————————# 解压后缀为 .zip 的压缩包，如提示命令不存在，请安装 yum install unzip -y / apt-get install unzip -y，注意 zip 和 unzip 是分开的unzip log.zip # 更多的命令可以用 tar --help / gzip --help / unrar --help / unzip --help 来查看。# 压缩 文件/文件夹 示例# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar 压缩包tar -cf log.tar log.txttar -cf log.tar log————————————————————————————————————————————————————————————————————————————# 如果要压缩多个文件和文件夹，那么只需要在后面一直加下去即可tar -cf log.tar log.txt doub.txt log bash————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar.xz 压缩包，以下的其他后缀压缩命令都是一样tar -cJf log.tar.xz log.txttar -cJf log.tar.xz log————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar.gz 压缩包tar -czf log.tar.gz log.txttar -czf log.tar.gz log————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.gz 压缩包gzip log.gz log.txtgzip log.gz log————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.tar.bz 压缩包暂时没查到————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.bz / log.tar.bz / log.bz2 / log.tar.bz2压缩包bzip2 -z log.txtbzip2 -z log tar cjf log.tar.bz2 log.txttar cjf log.tar.bz2 log————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.Z / log.tar.Z 压缩包compress log.txtcompress log tar cZf log.tar.Z log.txttar cZf log.tar.Z log————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.rar 压缩包，如提示命令不存在，请安装 yum install rar -y / apt-get install rar -y ，注意 rar 和 unrar 是分开的unrar a log.rar log.txtunrar a log.rar log————————————————————————————————————————————————————————————————————————————# 分别压缩当前目录下的 log.txt文件 / log文件夹为 log.zip 压缩包，如提示命令不存在，请安装 yum install zip -y / apt-get install zip -y ，注意 zip 和 unzip 是分开的zip log.zip log.txtzip log.zip log # 更多的命令可以用 tar --help / gzip --help / rar --help / zip --help 来查看。 网络工具wget 多功能下载工具 wget 是Linux系统最常用的工具之一，命令行方式的多功能下载工具，支持HTTP，HTTPS和FTP协议。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 只介绍最常用的参数# 如果提示命令不存在，那么使用 yum install wget -y / apt-get install wget -y 来安装（有一些非常精简的系统可能会没装） -b ：启动后，后台下载-q ：安静模式（不输出任何信息）-c ：断点续传下载文件-O ：指定下载后的文件名（可使用绝对路径目录+文件名）-P ：指定下载后的文件目录（-P只能指定下载目录，并不能指定文件名）-t ：设置重试次数（0代表无限）-T ：设置超时时间（单位：秒）-N ：只获取比本地新的文件（新的覆盖旧的）-4 ：仅连接至 IPv4地址-6 ：仅连接至 IPv6地址--limit-rate=xxxk :限制下载速度（k代表KB/S）--post-data ：通过POST方式发送数据--no-check-certificate ：不验证服务器的SSL证书 # 更多的命令可以用 wget --help 来查看。# 示例# 下载一个文件到当前目录wget https://softs.pw/100MB.bin # 下载文件到当前目录并重命名为 200MB.binwget -O \"200MB.bin\" https://softs.pw/100MB.bin # 下载文件到 /root目录（-P只能指定下载目录，并不能指定文件名）wget -P \"/root\" https://softs.pw/100MB.bin # 下载文件到 /root/doubi目录并重命名为 200MB.binwget -O \"/root/doubi/200MB.bin\" https://softs.pw/100MB.bin # 下载文件完成之前 wget进程结束了，那么可以使用断点续传重新下载中断的文件（前提是下载服务器支持断点续传）wget -c https://softs.pw/100MB.bin# 通过后台下载文件到 /root/doubi目录并重命名为 200MB.binwget -b -O \"/root/doubi/200MB.bin\" https://softs.pw/100MB.bin# Continuing in background, pid 2333.# Output will be written to `wget-log'.# 后台下后，你可以使用以下命令来查看下载进度：tail -f wget-log # 有时候一些Linux系统中的SSL证书不完整，会导致下载一些 HTTPS网站文件的时候会验证SSL证书失败，可以这样做# 不验证服务器SSL证书，下载文件到当前目录并重命名为 200MB.binwget --no-check-certificate -O \"200MB.bin\" https://softs.pw/100MB.bin # 使用wget发送POST请求数据wget --post-data \"user=doubi&amp;passwd=23333\" https://xxx.xx/ # 下载文件到当前目录 并仅通过IPv4连接 只获取比本地新的文件，限速 200KB/Swget --limit-rate=200k -N -4 https://softs.pw/100MB.bin # 下载文件到当前目录 并重试次数为 1，超时时间为 2秒wget -t1 -T2 https://softs.pw/100MB.bin # 通过 wget来获取服务器的外网IP（-qO- 代表运行完会输出下载的信息，并不会保存到本地文件）wget -qO- ipinfo.io/ip # 更多的命令可以用 wget --help 来查看。 curl HTTP工具 curl是Linux系统一个利用URL规则在命令行下工作的文件传输工具，是一款很强大的HTTP命令行工具。它支持文件的上传和下载，是综合传输工具，但习惯称curl为下载工具。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 只介绍最常用的参数# 如果提示命令不存在，那么使用 yum install curl -y / apt-get install curl -y 来安装（有一些非常精简的系统可能会没装） -s ：安静模式（不会输出任何信息）-C ：断点续传下载文件-o ：输出写入到文件中-O ：输出写入到文件，文件名为 远程文件的名称-k ：不验证服务器SSL证书-T ：上传文件-4 ：仅连接至 IPv4地址-6 ：仅连接至 IPv6地址-m ：设置传输总时间（单位：秒）--retry ：设置重试次数--data ：通过POST方式发送数据--limit-rate xxxK ：限制下载速度（K代表KB/S） # 更多的命令可以用 curl --help 来查看。# 示例# 获取当前服务器的外网IPcurl ipinfo.io/ip # 获取一个文件保存到当前目录中wget -O https://softs.pw/Bash/ssr.sh # 获取一个文件保存到 /root/doubi目录中 并修改文件名为 233.shcurl -o \"/root/doubi/233.sh\" https://softs.pw/Bash/ssr.sh # 下载文件完成之前 curl进程结束了，那么可以使用断点续传重新下载中断的文件（前提是下载服务器支持断点续传）curl -C -O https://softs.pw/100MB.bin # 有时候一些Linux系统中的SSL证书不完整，会导致访问/下载一些 HTTPS网站/文件的时候会验证SSL证书失败，可以这样做# 不验证服务器SSL证书，下载文件到当前目录并重命名为 233.shcurl -k -o \"233.sh\" https://softs.pw/Bash/ssr.sh # 使用curl发送GET请求数据curl https://xxx.xx/?user=doubi # 使用curl发送POST请求数据curl --data \"user=doubi&amp;passwd=23333\" https://xxx.xx/ # 下载文件到当前目录 并仅通过IPv4连接，限速 200KB/Scurl --limit-rate 200K -4 https://softs.pw/100MB.bin # 下载文件到当前目录 并重试次数为 1，超时时间为 2秒curl --retry 1 -m 10 https://softs.pw/100MB.bin # 更多的命令可以用 curl --help 来查看。 netstat 查看链接和端口监听等信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455-n ：不显示别名（主机名/域名以 数字或IP显示）-e ：显示其他/更多信息-p ：显示进程PID/进程名-c ：持续输出（设置后会每隔 1秒输出一次，Ctrl+C 终止）-l ：显示正在监听的套接字-a ：显示全部信息 # 下面这些就不很常用了。-r ：显示路由表-i ：显示网络接口（网卡）-g ：显示多播组信息-s ：显示网络统计-M ：显示伪装连接-v ：显示正在进行的工作 # 更多的命令可以用 netstat --help 来查看。# 示例# 显示当前服务器的所有连接信息netstat -a # 显示当前服务器的所有 TCP连接信息netstat -at # 显示当前服务器的所有 UDP连接信息netstat -au# 一般来说经常使用这个命令：# 显示当前服务器的所有正在监听 TCP端口的信息，并且 显示进程PID和进程名，但不显示别名（域名以IP显示），这个命令算是最常用的了。netstat -lntp# 显示监听 80端口的进程PID和进程名，grep是匹配并显示 符合关键词的行。netstat -lntp|grep \":80\"# 显示 ssh的监听情况，grep是匹配并显示 符合关键词的行。netstat -lntp|grep \"ssh\"# 每隔 1秒显示一次当前服务器的所有连接信息netstat -c # 每隔 1秒显示一次当前服务器的所有 TCP连接信息netstat -ct # 每隔 1秒显示一次当前服务器的所有 UDP连接信息netstat -cu # 显示当前服务器的路由表netstat -r # 显示当前服务器的网络接口信息（网卡）netstat -i # 显示当前服务器的网络统计信息netstat -s 名词解释 123456789101112131415161718192021222324252627282930Proto ：连接协议（tcp/udp是IPv4，tcp6/udp6是IPv6）Recv-Q ： 接收队列（基本都是0，如果不是代表堆积）Send-Q ：发送队列（基本都是0，如果不是代表堆积）Local Address ：本地地址和端口Foreign Address ：对外地址和端口State ：连接状态PID/Program name ：进程PID/进程名LISTEN# 监听来自远程连接的 TCP端口连接请求SYN-SENT# 在发送连接请求后，等待匹配的连接请求SYN-RECEIVED# 在收到和发送一个连接请求后，等待对方对连接请求的确认ESTABLISHED# 代表一个打开的连接FIN-WAIT-1# 等待远程 TCP连接中断请求，或先前的连接中断请求的确认FIN-WAIT-2# 从远程 TCP等待连接中断请求 CLOSE-WAIT# 等待从本地用户发来的连接中断请求 CLOSING# 等待远程TCP对连接中断的确认 LAST-ACK# 等待原来的发向远程TCP的连接中断请求的确认 TIME-WAIT# 等待足够的时间，以确保远程TCP接收到连接中断请求的确认 CLOSED# 没有任何连接状态（或者关闭了连接） 系统命令ps 查看进程信息12345678# 更多的命令可以用 man ps 来查看。# 示例# 显示当前进程信息ps -ef # 显示 ssh 进程（ grep -v grep 表示排除关键词grep，因为使用 grep匹配ssh，也会把grep自己的进程匹配进去的）ps -ef|grep -v grep|grep ssh 名词解释 12345678UID ：启动进程的用户PID ：进程标识符（进程 1代表init 是整个系统的父进程）PPID ：父进程标识符（进程 1代表init 是整个系统的父进程）C ：CPU占用率 %STIME ：启动进程的日期TTY ：终端号TIME ：进程运行时间（非休眠状态）CMD ：启动进程的命令（或进程名/进程程序所在目录） kill 结束进程1234567891011121314151617# 当我们想要结束一个进程的时候，我们可以用 kill 命令# PID是每个进程的一个唯一标识符，可以使用上面的 ps 命令来查看你要结束进程的PID。 # 假设我们要结束 Nginx的进程，那么这样做（ grep -v grep 表示排除关键词grep，因为使用 grep匹配ssh，也会把grep自己的进程匹配进去的）：ps -ef|grep -v grep|grep \"nginx\" # 输出示例UID PID PPID C STIME TTY TIME CMD #注意使用上面命令的话是不会显示表头这一行的，我只是为了更好理解加上的root 2356 1 0 04/03 ? 00:03:12 nginx # 然后我们可以看到第二列的 PID 进程标识符，然后我们 kill 即可。kill -9 2356 # 中断进程 -2 相当于 程序运行在前台，然后输入 Ctrl+C 的效果，但是进程有权利忽略，所以不一定能结束进程kill -2 PID# 强制结束进程 -9 ，注意：强制结束某个进程后，可能会造成进程数据丢失等问题！kill -9 PID free 查看内存使用信息12345678910111213141516171819202122232425262728293031323334353637-b ：以 字节(bytes/B) 为单位显示-k ：以 KB 为单位显示-m ：以 MB 为单位显示-g ：以 GB 为单位显示--tera ：以 TB 为单位显示-h ：以 人类易读的方式输出--si ：以 1000为单位转换，而不是 1024（1MB=1*1024KB改成 1MB=1*1000KB）-t ：显示 内存总数 行-s 时间 ：每隔 X秒输出一次（重复输出监视内存，使用 Ctrl+C 终止）-c 次数 ：每隔 1秒输出 X次 # 更多的命令可以用 free --help 来查看。# 示例# 显示当前系统内存（默认 free = free -k，单位为 KB）free # 以单位 B/KB/MB/GB/TG 显示当前系统内存free -b / free -k / free -m / free -g / free --tera # 以人类易读的方式 显示当前系统内存free -h# 以 1000为单位转换并使用 MB为单位 显示当前系统内存（1MB=1*1024KB改成 1MB=1*1000KB）free -m --si # 每隔 3秒并使用 MB为单位 显示一次当前系统内存free -ms 3 # 每隔 1秒并使用 MB为单位 显示 5次当前系统内存free -mc 5 # 每隔 2秒并使用 MB为单位 总共显示 6次当前系统内存free -m -c 6 -s 2 # 更多的命令可以用 free --help 来查看。 名词解释 123456789101112131415161718192021222324252627# 说明示例 total used free shared buffers cachedMem: 244M 232M 12M 0B 33M 69M-/+ buffers/cache: 129M 115MSwap: 627M 1.7M 626M# Mem 行，表示物理内存统计total :系统 总物理内存used :系统 已分配物理内存（但非全部都在使用，包含buffers好cached）free :系统 未分配物理内存shared :系统 共享内存，一般都是 0buffers :系统 分配但未使用的 buffers数量cached :系统 分配但未使用的 cached数量 # -/+ buffers/cache 行，表示物理内存的缓存统计used :系统 实际使用的内存# user= Mem行 used-buffers-cached（232-33-69=130，因单位转换问题 所以会有一点差距）free :系统 实际可用的内存# free= Mem行 free+buffers+cached（12+33+69=114，因单位转换问题 所以会有一点差距） # 所以我们看系统的真实 使用/剩余内存 只需要看这一行即可！ # Swap 行，表示硬盘的交换分区（虚拟内存）统计total :系统 总虚拟内存used :系统 已分配虚拟内存free :系统 未分配虚拟内存 # KVM虚拟化的VPS，可以用这个教程手动添加 SWAP虚拟内存：https://doub.bid/linux-jc7/ date 查看/设置 系统时间123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106 -d ：以指定的时间格式 显示时间 -f ：显示 DATE FILE文件中的每行时间（我也不懂） -r ：显示 文件/文件夹 最后修改时间 -s ：设置 系统时间 -u ：显示 UTC时间 # 时间格式 %% - 显示字符%%a - 星期几的缩写(Sun..Sat)%A - 星期几的完整名称（Sunday...Saturday）%b - 月份的缩写(Jan..Dec)%B - 月份的完整名称(January..December)%c - 日期与时间。只输入date指令也会显示同样的结果%C - 世纪(年份除100后去整) [00-99]%d - 日期(以01-31来表示)。%D - 日期(含年月日)。%e - 一个月的第几天 ( 1..31)%F - 日期，同%Y-%m-%d%g - 年份(yy)%G - 年份(yyyy)%h - 同%b%H - 小时(00..23)%I - 小时(01..12)%j - 一年的第几天(001..366)%k - 小时( 0..23)%l - 小时( 1..12)%m - 月份(01..12)%M - 分钟(00..59)%n - 换行%N - 纳秒(000000000..999999999)%p - AM or PM%P - am or pm%r - 12小时制时间(hh:mm:ss [AP]M)%R - 24小时制时间(hh:mm)%s - 从00:00:00 1970-01-01 UTC开始的秒数%S - 秒(00..60)%t - 制表符%T - 24小时制时间(hh:mm:ss)%u - 一周的第几天(1..7); 1 表示星期一%U - 一年的第几周，周日为每周的第一天(00..53)%V - 一年的第几周，周一为每周的第一天 (01..53)%w - 一周的第几天 (0..6); 0 代表周日%W - 一年的第几周，周一为每周的第一天(00..53)%x - 日期(mm/dd/yy)%X - 时间(%H:%M:%S)%y - 年份(00..99)%Y - 年份 (1970…)%z - RFC-2822 风格数字格式时区(-0500)%Z - 时区(e.g., EDT), 无法确定时区则为空 # 更多的命令可以用 date --help 来查看。使用示例：# 显示 当前系统时间date# 输出：Wed Apr 5 12:38:44 CST 2017 # 显示当前系统的 UTC时间date -u# 输出：Wed Apr 5 04:30:06 UTC 2017# 显示 log.txt 文件的最后修改时间date -r log.txt# 显示 当前日期的年份date +%Y# 输出：2017 # 显示 当前日期的月份date +%m# 输出：4 # 显示 各种格式类型的日期date +%D# 输出：04/05/17 date +%Y-%m-%d# 输出：2017-04-05 date +%m/%d/%y# 输出：04/05/17 date +%m/%d/%Y# 输出：04/05/2017 # 显示 Unix时间戳date +%s# 输出：1491367399 # 显示一个完整的时间（年、月、日、小时、分钟、秒钟、周几 时区）date \"+%Y-%m-%d %H:%I:%S %u %Z\"# 输出：2017-04-05 12:12:15 3 CST # 设置 系统时间（年、月、日）date -s \"2017-04-05\" # 设置 系统时间（小时、分钟、秒钟）date -s \"10:29:05\" # 设置 系统时间（年、月、日、小时、分钟、秒钟）date -s \"2017-04-05 10:29:05\" # 更多的命令可以用 date --help 来查看。再教你们一个修改时区为上海（北京）时区的方法：cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime然后再用 date 查看时间，就会发现时区变为 CST 了。 chmod 修改 文件/文件夹 权限12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152-c :只输出被改变权限的文件信息-f :当chmod不能改变文件模式时，不通知文件的用户-R :可递归遍历子目录，把修改应到目录下所有文件和子目录-v :无论修改是否成功，输出每个文件的信息 # 操作符号： + :添加某个权限。- :取消某个权限。= :赋予给定权限并取消其他所有权限（如果有的话）。 # 权限设置字母： r :可读w :可写x :可执行X :只有目标文件对某些用户是可执行的或该目标文件是目录时才追加x 属性s :在文件执行时把进程的属主或组ID置为该文件的文件属主。方式“u＋s”设置文件的用户ID位，“g＋s”设置组ID位t :保存程序的文本到交换设备上u :当前用户的权限g :当前用户同组的权限o :其他用户的权限 # 权限设定数字： # 数字表示的属性含义：0 ：表示没有权限1 ：表示可执行权限2 ：表示可写权限4 ：表示可读权限 # 然后将其相加，所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。# 如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。 # 更多的命令可以用 chmod --help 来查看。使用示例：# 当需要运行 可执行的脚本或者程序（比如 Go语言编写的软件）的时候，需要赋予执行权限chmod +x ssr.sh # 赋予 log.txt 文件可读权限chmod 444 log.txt # 赋予 /ver/log 文件夹 可读、可写权限chmod 666 log.txt # 赋予 /home/www 文件夹 可读、可写、可执行权限chmod 777 log.txt # 赋予 /home/www 文件夹极其所有子目录和文件 可读、可写、可执行权限chmod -R 777 log.txt# 更多的命令可以用 chmod --help 来查看。 uname 获取操作系统信息12345678910111213141516171819202122232425-a：显示 全部信息-m：显示 系统位数-n：显示 主机名称-r：显示 操作系统的发行编号-s：显示 操作系统的名称-v：显示 操作系统的版本-p：输出 处理器类型 或\"unknown\"-i：输出 硬件平台 或\"unknown\"-o：输出 操作系统名称 # 更多的命令可以用 uname --help 来查看# 示例#在使用 uname 的时候，相当于是使用 uname -sunameuname -auname -m uname -nuname -runame -suname -vuname -puname -iuname -o df du 获取磁盘信息123456# 查看磁盘各分区信息df -h# 查看foo目录的大小du -sh foo# 查看当前目录各个文件、目录的大小du -sh * 参考Linux 常用命令简单介绍 —— 基础篇","tags":[{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.ajavac.com/tags/Linux/"}]},{"title":"Mac OS 日常记录","date":"2017-04-08T10:34:45.000Z","path":"2017/04/08/Common/mac/","text":"科学上网工具ShadowsocksX-NG 单独设置git的代理设置代理1234567git config --global https.proxy http://127.0.0.1:1080git config --global https.proxy https://127.0.0.1:1080# socks5git config --global http.proxy 'socks5://127.0.0.1:1080'git config --global https.proxy 'socks5://127.0.0.1:1080' 取消代理123git config --global --unset http.proxygit config --global --unset https.proxy 设置终端的代理临时代理12345# 命令执行中,一次性的代理http_proxy=http://localhost:1087 curl www.google.comhttps_proxy=http://localhost:1087 curl https://www.google.com# 终端使用过程中,一次性的代理export http_proxy=http://127.0.0.1:1087 https_proxy=http://127.0.0.1:1087 永久全局代理在.zshrc等文件最后添加以下环境变量1export http_proxy=http://127.0.0.1:1087 https_proxy=http://127.0.0.1:1087 自定义代理命令在.zshrc等文件最后添加以下别名设置1alias proxy='export http_proxy=http://127.0.0.1:1087 https_proxy=http://127.0.0.1:1087' 以后需要代理的时候只要输入proxy命令,当前终端下之后的命令执行都会进行代理 语言选择 如果在首次使用 mac OS 的时候选择了中文作为第一语言，然后之后又设置英文作为操作系统第一语言，每次系统更新之后都可能出现部分系统界面显示中文（关机、重启、登录） 解决办法如下（在终端中输入命令）： 1sudo \"/System/Library/CoreServices/Language Chooser.app/Contents/MacOS/Language Chooser\" 然后重新选择第一语言，问题解决 常用软件 Home Brew Home Brew Cask Alfred 常用命令","tags":[{"name":"Mac","slug":"Mac","permalink":"https://blog.ajavac.com/tags/Mac/"}]},{"title":"《Effective Java》读书笔记——第3章","date":"2017-03-27T15:13:02.000Z","path":"2017/03/27/EffectiveJava/chapter3/","text":"对于所有对象都通用的方法No.8 覆盖equals时请遵守通用约定 类具有自己特有的”逻辑相等”概念时应该覆盖Object.equals方法 覆盖equals时，必须要遵守它的通用约定： 自反性（reflexive）对于任何非null的引用值x，x.equals(x)必须为true 对称性（symmetric）对于任何非null的引用值x和y，当且仅当x.equals(y)为true时，y.equals(x)必须返回true 传递性（transitive）对于任何非null的引用值x、y和z，如果x.equals(y)为true，并且y.equals(z)为true，那么x.equals(z)也必须为true 一致性（consistent）只要操作对象信息未被修改，多次调用equals结果必须一致 非空性（Non-nullity）对于任何非null的引用值x，x.equals(null)必须为false 实现高质量equals方法的诀窍： 使用==检查“参数是否为这个对象的引用” 使用instanceof检查”参数是否为正确类型” 把参数转换成正确类型 检查参数中的关键（significant）域与该对象中对应的域是否相匹配 检查是否达到了对称性、传递性、一致性的要求 覆盖equals时总要覆盖hashCode 不要企图让equals方法过于智能 不要将equals声明中的Object对象替换成其他的类型 使用@Override注解 No.9 覆盖equals时总要覆盖hashCode 每个覆盖了equals方法的类中，也必须覆盖hashCode方法 约定： 应用程序的一次执行中，对同一个对象的调用多次，hashCode方法必须始终如一的返回同一个整数。在同一个程序的多次执行过程中，每次执行锁返回的整数可以不一致 如果两个对象的根据equals方法比较是相等的，那么调用它们的hashCode方法的整数结果也必须相等 如果两个对象的根据equals方法比较是不相等的，那么调用它们的hashCode方法的整数结果不一定要不相等 推荐散列算法: int result = 17; 为所有的域分别计算int类型的散列码(若是对象则调用其hashCode()方法): boolean类型：f ? 1 : 0 byte、char、short、int类型：(int) f long类型：(int) (f ^ (f &gt;&gt;&gt; 32)) float类型：Float.floatToIntBits(f) double类型：Double.doubleToLongBits(f)后按long类型处理 引用类型(对象)：调用其hashCode()方法（若域为null则为0） 数组类型：对每个元素当做单独的域处理或者使用Arrays.hashCode()方法 将每个域计算出的散列码合并：result = 31 * result + c; 返回result 验证该散列算法是否符合约定，“相等的实例是否都具有相等的散列码” 总结： 相等的对象具有相等的散列码 不相等的对象的散列码不一定不相等 不要试图从散列码计算中排除掉一个对象的关键部分来提高性能 一个比较好的散列算法：31*i，因为31*i == (i &lt;&lt; 5) - 1 No.10 始终要覆盖toString toString 方法旨在返回一个”简洁的，但信息丰富，并且易于阅读的表达形式”，建议所有的子类都覆盖这个方法 toString 方法应该返回对象中包含的所有值得关注的信息 当对象被传递给println、printf、字符串级联操作符（+）、assert、调试器打印等情况时，toString方法会被自动调用 No.11 谨慎地覆盖clone 所有实现了Cloneable接口的类都应该用一个公有的方法覆盖clone，此公有方法1首先应该调用super.clone()，然后修正任何需要修正的域。 其他接口都不应该扩展（extends）这个接口（Cloneable） 为了继承而设计的类也不应该实现（implement）这个接口（Cloneable） No.12 考虑实现Comparable接口 对实现了Comparable接口的对象数组a进行排序只需要Arrays.sort(a); 如果在编写一个值类，它具有非常明显的内在排序关系，那么应该坚决考虑实现这个接口","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Effective_Java","slug":"Effective-Java","permalink":"https://blog.ajavac.com/tags/Effective-Java/"},{"name":"book","slug":"book","permalink":"https://blog.ajavac.com/tags/book/"}]},{"title":"Java 8 新特性","date":"2017-03-26T10:35:55.000Z","path":"2017/03/26/Java/java8/","text":"Oracle 公司于 2014 年 3 月 18 日发布 Java 8 ，添加了许多新特性 序号 特性 说明 1 Lambda表达式 允许函数作为参数传递给方法 2 默认方法 在接口里面实现方法 3 方法引用 简化代码 4 函数式接口 使Java支持真正的函数式编程 5 Stream 使Java支持真正的函数式编程 6 Base64 提供Base64编码、解码方法 7 Optional类 用来解决NullPointException 8 新日期时间API 使用方便程度不如joda-time 9 Nashorn JavaScript 引擎 新JS引擎，一般情况下用不上 Lambda表达式12345678// 类型声明(int a, int b) -&gt; a + b;// 类型不声明(a, b) -&gt; a + b;// 大括号,超过一行表达式的情况下必须要大括号(a, b) -&gt; &#123; return a + b;&#125;;// 最简情况下不需要括号a -&gt; 3*a; 默认方法 默认方法就是借口可以实现方法，其实现类可以不实现该方法。目的是为了解决接口的修改与现有的实现不兼容的问题。 默认接口方法：使用default关键字标识 默认静态方法：使用static关键字标识 12345678910111213// 用例public interface Test &#123; // 默认接口方法 default void defaultMethod()&#123; System.out.println(\"Test default\"); &#125; // 默认静态方法 static void staticMethod()&#123; System.out.println(\"Test static\"); &#125;&#125; 方法引用 构造器引用：Test::new 方法引用：Test::test 函数式接口 函数式接口就是一个具有一个方法的普通接口，可以被隐式转换为lambda表达式 JDK 8 新增了许多函数式接口在java.util.function中 Stream Java 8 新增了一个概念称为流Stream，可以以一种声明的方式处理数据 生成流的方法： 串行流：stream() 并行流：parallelStream() 流的方法： 遍历：forEach() 映射每个元素对应的结果：map() 过滤出元素：filter() 指定获取数量：limit() 排序：sorted() 将流转换为集合：collect() 统计：summaryStatistics() 计算个数：count() Base64 Java 8 内置了三种Base64编解码器 基本 输出被映射到一组字符A-Za-z0-9+/，编码不添加任何行标，输出的解码仅支持A-Za-z0-9+/ 编码器：Base64.getEncoder() 解码器：Base64.getDecoder() URL 输出映射到一组字符A-Za-z0-9+_，输出是URL和文件 编码器：Base64.getUrlEncoder() 解码器：Base64.getUrlDecoder() MIME 输出映射到MIME友好格式。输出每行不超过76字符，并且使用’\\r’并跟随’\\n’作为分割。编码输出最后没有行分割 编码器：Base64.getMimeEncoder() 解码器：Base64.getMimeDecoder() Optional类 Optional类的引入很好的解决空指针异常 新日期时间API 旧的Java中日期时间API设计比较差（非线程安全、设计差、时区处理麻烦），所以提出了新的日期时间API Java 8 在java.time包下提供了许多新的日期时间API，主要有 java.time.LocalDate java.time.LocalTime java.time.LocalDateTime java.time.ZonedDateTime PS：个人觉得还是joda-time使用方便 Nashorn JavaScript 引擎 一个JavaScript引擎，用来在Java中调用JavaScript或者在JavaScript中调用Java。与之前的Rhino实现相比，带来2到10倍的性能提升。一般开发不怎么用到。","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"JDK之String","date":"2017-03-26T10:35:55.000Z","path":"2017/03/26/Java/jdk_string/","text":"java.lang.String是Java编程中最常见的类之一 Java中使用Unicode字符集，使用UTF-16的编码实现方式，一个基本多语言平面（Basic Multilingual Plane，简称BMP）字符占用一个char（16bit），一个辅助平面（Supplementary Plane）字符占用两个char（16bit * 2）。 比如说emoji表情就占用了两个char String的特点 是一个不可变类，一旦创建便不可改变 类定义为public final class String，是一个终类，不可被继承 实现了java.io.Serializable接口，可序列化和反序列化 实现了java.lang.Comparable&lt;String&gt;接口，可以进行比较和排序 实现了java.lang.CharSequence接口，是一个可读的字符序列 String最多可存储2^31-1个char(每个char占用16bit) String最多可存储(2^30-1)~(2^31-1)个Unicode字符，原因在于Java中的Unicode编码方式（UTF-16），一个Unicode字符最多可能占用2个char ​ 注意 length()方法获取的是String字符串中char的长度 String不宜直接存储密码等敏感数据，有dump风险，可用char[]存储（用完后清除），或者对敏感数据进行加盐hash","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"Java基础","date":"2017-03-25T13:55:25.000Z","path":"2017/03/25/Java/java_basic/","text":"数据类型内置类型——基本数据类型 名称 大小 默认值 取值说明 boolean 1bit false 布尔值，作二元判断，true或者false byte 8bit 0x00 有符号整数，范围-128 ~ 127，转换成int时需注意高位补齐 short 16bit 0 有符号整数，范围-32768 ~ 32767 char 16bit \\u0000 Unicode字符，少数字符使用2个char表示 int 32bit 0 有符号整数，范围-2^31 ~ (2^31 - 1) float 32bit 0.0F 浮点数，范围1.4E-45~3.4028235E38 long 64bit 0L 有符号整数，范围-2^63 ~ (2^63 - 1) double 64bit 0.0D 浮点数，范围4.9E-324~1.7976931348623157E308 ps：浮点数有精度，要不失真使用java.math.BigDecimal和java.math.BigInteger 扩展类型——引用数据类型形如: String str = &quot;I am a String !&quot;; 三大特性面向对象编程有三大特性： 封装 继承 多态 类访问权限 同一个类 同一个包 不同包的子类 不同包的非子类 private ✔️ default ✔️ ✔️ protected ✔️ ✔️ ✔️ public ✔️ ✔️ ✔️ ✔️ 多态 所谓多态意指相同的消息给予不同的对象会引发不同的动作称之。 ——维基百科 存在的必要条件： 继承 重写 向上转型（父类引用指向子类对象） 实现方式： 重写 接口 抽象类和抽象方法 比如：List&lt;String&gt; list = new ArrayList&lt;&gt;)(); 重载（Overload）、重写（Override）重载(Overload)指的是一个类里面有同名方法，其参数不同，除了参数要独一无二外没什么特殊限制。 重写(Override)指的是子类对父类方法的实现进行重新编写。 区别 重载（Overload） 重写（Override） 参数列表 必须修改 不可修改 返回类型 可以修改 不可修改 异常 可以修改 可以减小异常范围（子类异常或无异常） 访问权限 可以修改 可以降低访问限制(如protected–&gt;public) Java内存模型 Java内存模型的主要目标是定义程序中各个变量（不包括局部变量，因为局部变量是线程私有的，不会被共享，不存在竞争问题）的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 所有变量都存储在主内存（Main Memory）中 每条线程有自己的工作内存（Working Memory），保存了该线程用到的变量的主内存副本拷贝（不会整个对象拷贝） 线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量 不同线程间不能直接访问对方工作内存中的变量，线程间的变量值得传递需要通过主内存来完成 Object方法 Java是单根继承结构，有一个终极基类Object，它的存在保证所有对象都具备某些功能（具有一个共同接口），使得垃圾回收器的实现变得容易。 方法 作用 getClass 获得运行时对象的类型 hashCode 计算对象的hash值 equals 判一个对象是否与自身相等 toString 将对象表示为字符串,在一些字符串操作的地方会自动调用 notify (当该对象作为锁时可用)唤醒该对象监视下的一个等待的线程 notifyAll (当该对象作为锁时可用)唤醒该对象监视下的所有等待的线程 wait (当该对象作为锁时可用)线程进入等待状态，可以设置等待时长 clone 复制对象，需要实现Cloneable接口 finalize 对象终结时候执行的方法 sleep、notify、wait sleep(静态方法) notify wait 所属类 Thread Object Object 作用 程序停止一定时间（传入参数），让给其他程序执行 唤醒一个等待的线程，不确定是哪个 进入等待状态直到被唤醒，若带参数则会自动唤醒 锁的持有情况 不变 不变 放弃 String、StringBuffer、StringBuilder String StringBuffer StringBuilder 是否可变 ❌ ✔️ ✔️ 线程安全 ✔️ ✔️ ❌ 内部实现 final修饰的char数组 char数组，自动扩容、拷贝 char数组，自动扩容、拷贝 作用 表示字符串 构建字符串，同步，单线程下效率较StringBuilder低 构建字符串，非同步，效率高 提防+或者+=连续拼接大量字符串，会使得性能低下 ，大量字符串拼接应考虑StringBuilder（单线程下首选）或者StringBuffer（需要线程安全的情况下） Java编译会对的+或者+=字符串拼接进行优化（优化成StringBuilder或者StringBuffer），所以简单的拼接可以直接使用 原子性、可见性和有序性 原子性（Atomicity）：基本数据类型的读写具备原子性（虽然非协定要求，但是long和double在现代虚拟机中也实现了原子性），在synchronized代码块之间的操作也具备原子性 可见性（Visibility）：一个线程修改了共享变量的值，其他线程能立刻得知这个修改，volatile保证的多线程操作时变量的可见性，而普通变量则不能保证这一点，synchronized和final也可以保证可见性 有序性（Ordering）：如果在本线程内观察，所有的操作都是有序的（县线程内表现为串行的语义，Within-Thread As-If-Serial Semantics）。如果在一个线程中观察另一个线程，所有操作都是无序的（”指令重排序现象“和”工作内存与主内存同步延迟现象“）。volatile和synchronized来保证线程间操作的有序性 先行发生（happens-before）原则如果连个操作之间的关系不在以下规则之中，并且无法从以下规则推到出来，它们就没有顺序性保障，虚拟机可以对它们随意的进行重排序 程序次序规则（Program Order Rule）：在一个线程内，按照程序代码的控制流顺序，书写在前面的代码先行发生于书写在后面的代码 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面（时间上先后）对于同一个锁的lock操作 volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面（时间上先后）对这个变量的读操作 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作 线程终止规则（Thread Termination Rule）：线程中的每一个动作都先行发生于对此线程的终止检测 线程中断规则（Thread Interruption Rule）：对线程中interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 对象终结规则（Finalizer Rule）：一个对象的初始化完成先行于它的finalize()方法的开始 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那么，操作A先行发生于操作C 一个操作”时间上的先发生“不代表这个操作会是”先行发生“；一个操作”先行发生“也不能代表这个操作”时间上的先发生“（指令重排序）。衡量并发安全问题不要受到时间顺序的干扰，一切必须以先行发生原则为准。 volatile和synchronized 关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制 一个变量被声明为volatile后具备两种特性： 保证此变量对所有线程的可见性，即修改可以被立即得知，此变量在各个线程的工作内存中不存在一致性问题（每次使用前都要先刷新） 禁止指令重排序优化 因为在Java中的运算并非原子操作，所以volatile变量的运算在并发下一样是不安全的，volatile只能保证可见性，在不符合以下规则的场景下需要通过加锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性： 运算结果不依赖变量的当前值，或者能保证只有单一线程修改变量的值 变量不需要与其他的状态变量（可能存在不一致）共同参与不变约束 volatile与synchronized的区别 volatile synchronized 是否加锁 否 是 是否造成线程阻塞 否 是 是否具备可见性 是 是 是否具备原子性 否 是 是否可以被编译器优化 否 是 同步机制重量级 轻 重 使用的地方 变量 变量、方法 线程间通信方式 同步：通过synchronized实现线程间通信 while轮询：不断地检测条件，会浪费CPU资源，存在可见性问题（可能造成死循环） wait/notify机制：存在通知过早问题，会打乱程序的执行逻辑 管道通信：类似消息传递机制，使用java.io.PipedInputStream和java.io.PipedOutputStream进行通信 线程的各种状态 Java语言定义了5种线程状态（新建、运行、等待、阻塞、结束），任意时间点，线程有且只能有其中一种状态。Java中一般使用抢占式的线程调度方式 新建（New）：创建后尚未启动的线程 运行（Runable）：包括Running和Ready 无限期等待（Waiting）：等待被其他线程显式地唤醒，进入该状态的方法有无参Thread.join()、无参Object.wait()和LockSupport.park()等 限期等待（Timed Waiting）：到时间后会自动唤醒，进入该状态的方法有Thread.sleep()、带参Thread.join()、带参Object.wait()、LockSupport.parkNanos()和LockSupport.parkUntil()等 阻塞（Blocked）：线程被阻塞了，等待获取到一个排他锁，在另一个线程放弃这个锁的时候发生 结束（Terminated）：已终止线程的状态，线程已经结束执行。 阻塞状态在等待另一个线程释放排它锁，而等待状态在等待时间到或者被唤醒。 关于Java中的finallyfinally可能没被执行 在try语句执行前程序就返回(结束了) 在try块中有System.exit(0),虚拟机停止 finally语句执行情况 finally语句在return语句执行之后return返回之前执行的 finally块中的return语句会覆盖try块中的return返回 如果finally语句中没有return语句覆盖返回值，那么原来的返回值可能因为finally里的修改而改变也可能不变(传值问题) try块里的return语句在异常的情况下不会被执行，这样具体返回哪个看情况 当发生异常后，catch中的return执行情况与未发生异常时try中return的执行情况完全一样 参考 《Thinking in Java》 《深入理解Java虚拟机》","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Basic","slug":"Basic","permalink":"https://blog.ajavac.com/tags/Basic/"}]},{"title":"Web大规模并发的解决思路","date":"2017-03-23T09:20:35.000Z","path":"2017/03/23/Common/web_seckill/","text":"特点：短时间内海量的请求，比如1秒5w请求（5wQPS） 大规模并发带来的挑战 请求接口的合理设计，动静态资源分离（CDN），负载均衡，分布式，使用内存数据库 快速反馈，合理设计，防止雪崩 重启和过载保护，拒绝超载的请求 防止作弊手段 一个账号多个请求，参与记录判断（只接受一个请求），使用Redis的watch乐观锁，或者使用队列实现 多个账号同个IP多个请求，使用验证码，禁止IP（容易误伤） 多个账号不同IP多个请求，数据挖掘清理僵尸号（有一些特点），提高活动门槛 火车票抢购，没有很好的解决方案，数据挖掘清理僵尸号 高并发下的数据安全——超发 使用悲观锁，但是性能低下 使用队列，容易爆队列 使用乐观锁，会增大CPU计算开销，但是是比较好的解决方案 参考【问底】徐汉彬：Web系统大规模并发——电商秒杀与抢购","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"Web","slug":"Web","permalink":"https://blog.ajavac.com/tags/Web/"},{"name":"Seckill","slug":"Seckill","permalink":"https://blog.ajavac.com/tags/Seckill/"}]},{"title":"HashMap的实现原理","date":"2017-03-23T06:48:33.000Z","path":"2017/03/23/Java/hash_map/","text":"简介 HashMap 是基于哈希表的 Map 接口的非同步实现，允许null作为键或值，不保证顺序恒久不变，是无序的。 数据结构Java中最基本的结构是数组和引用，HashMap就是通过这两个数据结构进行实现。实际上是一个“链表散列”的数据结构，是数组和链表的结合体（1.8后还加入了红黑树） HashMap 中存储数据的是一个Node&lt;K,V&gt;[] table数组，其中的内容可以是： null代表没有数据 Node&lt;K,V&gt;代表一个键值对（只有一个节点） Node&lt;K,V&gt;代表一个链表（有多个节点，2~8，当长度大于8转换成红黑树树） TreeNode&lt;K,V&gt;代表一个红黑树（有多个节点，8~） put方法get方法构造函数 HashMap() 构造一个初始容量16，负载因子为0.75的HashMap HashMap(int initialCapacity) 指定初始容量，负载因子为0.75 HashMap(int initialCapacity, float loadFactor) 指定初始容量和负载因子 初始容量 initialCapacity 和负载因子 loadFactor 两个参数共同决定了HashMap的最大容量：threshold = (int)(capacity * loadFactor); 当HashMap的元素数目超过threshold就需要进行resize()，把容量变为原来的两倍，元素的位置也会进行重新分配 loadFactor 表示散列表空间使用程度，越大空间利用率越高，但是查询效率越低 Fail-Fast 机制 HashMap 不是线程安全的，利用了modCount参数来记录每次修改，所以在用Iterator遍历过程中若发生并发修改会抛出ConcurrentModificationException异常 遍历方式 map.entrySet() 遍历entrySet，同时遍历key和value map.keySet() 效率低，遍历key，需要get才能获取value map.forEach((k,v)-&gt; System.out.println(k+&quot; : &quot;+v)); 效率高，需要JDK1.8以上 参考HashMap的实现原理","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Collection","slug":"Collection","permalink":"https://blog.ajavac.com/tags/Collection/"},{"name":"HashMap","slug":"HashMap","permalink":"https://blog.ajavac.com/tags/HashMap/"},{"name":"Map","slug":"Map","permalink":"https://blog.ajavac.com/tags/Map/"},{"name":"Hash","slug":"Hash","permalink":"https://blog.ajavac.com/tags/Hash/"}]},{"title":"《Effective Java》读书笔记——第2章","date":"2017-03-22T11:03:24.000Z","path":"2017/03/22/EffectiveJava/chapter2/","text":"创建和销毁对象No.1 考虑用静态工厂方法代替构造器静态工厂方法的优点： 它们有名称 不必再每次调用它们的时候都创建一个新对象 它们可以返回原返回类型的任何子类型的对象 在创建参数化类型实例的时候，它们使代码变得更加简洁 静态工厂方法的缺点： 类如果不含公有的或者受保护的构造器，就不能被子类化 它们与其他的静态方法实际上没有任何区别 静态工厂方法的一些惯用名称： valueOf of getInstance newInstance getType newType No.2 遇到多个构造器参数时要考虑用构建器 静态工厂方法和构造器都不能很好地扩展到大量的可选参数，JavaBeans模式有着严重的缺点（构造过程中可能处于不一致的状态，无法保证一致性），而Builder模式在大量可选参数的情况下可以满足可读性、一致性等要求。 总之，如果类的构造器或者静态工厂方法中具有多个参数（大于4个），设计这种类的时候，Builder模式就是不错的选择，尤其是在大多数参数是可选的时候。与传统的重叠构造器模式相比，Builder模式的客户端代码将更易于阅读和编写，构建器也比JavaBeans更加安全。 No.3 用私有构造器或者枚举类型强化Singleton属性 静态final域和私有构造器仍可能受到攻击 单元素的枚举类型已经成为实现Singleton的最佳方法。 No.4 通过私有构造器强化不可实例化的能力 工具类只有静态方法，实例化没有意义 企图通过将类做成抽象类来强制该类不可被实例化，这是行不通的。该类可以被子类化，并且其子类可以被实例化 将构造器私有化可以强化该类不可实例化的能力，但是它也使得该类不可被子类化 No.5 避免创建不必要的对象 要避免创建不必要的对象 如果对象是不可变的（immutable），它就始终可以被重用 可以通过静态工厂方法避免创建不必要的对象，比如Boolean.valueOf(String) 重用那些已知不会被修改的对象 优先使用基本类型而不是装箱基本类型，当心无意识的自动装箱 小对象的创建和回收动作是廉价的，所以不能绝对化的认为要避免创建对象，通过创建附加对象，提升程序的清晰性、简洁性和功能性，这通常是好事 实践： 比如String str= new String(&quot;test&quot;);就是很不好的例子，应该使用String str= &quot;test&quot;; 字符串的多次拼接应该考虑使用StringBuilder而不是简单的+或者+= ，除非只是一次性的拼接（编译器会自动优化） No.6 消除过期的对象引用 清空对象引用应该是一种例外，而不是一种规范行为 只要类是自己管理内存，程序员就应该警惕内存泄漏问题 内存泄漏的另一个常见来源是缓存 内存泄漏的第三个常见来源是监听器和其他回调 最好能在内存泄漏发生之前就知道如何预测此类问题，并阻止它们发生 解决方案： 使用弱引用WeakHashMap 后台线程定期清理没用的缓存项，比如LinkedHashMap的removeEldestEntry 对于更加复杂的缓存，必须直接使用java.lang.ref No.7 避免使用终结方法 终结方法（finalizer）通常是不可预测的，也是很危险的，一般情况下是不必要的 不应该依赖终结方法来更新重要的持久状态，因为不保证终结方法会被执行 使用终结方法有一个非常严重的（Severe）性能损失 最好使用显式终结方法，通常与try...finally结构结合起来使用，以确保及时终止。比如InputStream、OutputStream和java.sql.Connection 用途： 终结方法可以充当“安全网（safety net）“，在客户端为进行显式终止来正常结束的情况下释放资源，但是如果终结方法发现资源还未被终止，则应该在日志中记录这一警告，比如FileInputStream 第二个用途与对象的本地对等体（native peer）有关，终结方法应该完成所有必要的工作，释放关键的资源 注意： 如果子类覆盖了超类的终结方法，但是忘了手动调用超类的终结方法，那么超类的终结方法将永远的不到调用 可以将终结方法放在一个匿名的类中，它的唯一用途就是终结外围实例（enclosing instance），被称为终结方法守卫者（finalizer guardian）","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Effective_Java","slug":"Effective-Java","permalink":"https://blog.ajavac.com/tags/Effective-Java/"},{"name":"book","slug":"book","permalink":"https://blog.ajavac.com/tags/book/"}]},{"title":"关于MySQL中InnoDB的MVCC","date":"2017-03-22T10:35:40.000Z","path":"2017/03/22/MySQL/mysql_innod_mvcc/","text":"关于MySQL中InnoDB的MVCCMySQL中的实现 在InnoDB中的每行数据后都有额外的两个隐藏值来记录数据何时被创建(修改)和过期(删除)，这里的时间不是我们日常中的时间，而是事务的版本号，每开启一个新事务，版本号会递增。 在MySQL默认隔离级别Repeatable Read下： 设数据行创建版本号为create，删除版本号为delete，当前事务版本号为now SELECT，读取的数据行满足创建版本号&lt;=当前事务版本号，删除版本号为空或&gt;当前事务版本号，即 (create &lt;= now &amp;&amp; (delete == null || delete &gt; now)) INSERT，保存当前事务版本号为行的创建版本号（commit时生效），即create=now DELETE，保存当前事务版本号为行的删除版本号（commit时生效），即delete=now UPDATE，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行（commit时生效），即新行create=now旧行delte=now 通过MVVC，虽然每行记录需要额外的存储空间，但是减少了锁的使用，使读数据性能很好。在MySQL的RR级别中，解决了幻读的读问题（快照读）。 参考Innodb中的事务隔离级别和锁的关系","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ajavac.com/tags/MySQL/"},{"name":"DataBase","slug":"DataBase","permalink":"https://blog.ajavac.com/tags/DataBase/"},{"name":"Transaction","slug":"Transaction","permalink":"https://blog.ajavac.com/tags/Transaction/"}]},{"title":"spring 事务传播特性和隔离级别","date":"2017-03-22T10:35:00.000Z","path":"2017/03/22/MySQL/transaction/","text":"spring 事务传播特性和隔离级别事务四大特性: 原子性(Atomicity) :强调的事务的不可分割. 一致性(Consistency) :强调的事务的执行前后,数据库的的完整性保持一致. 隔离性(Isolation) :强调的事务的并发的访问,一个事务的执行,不应该受到另一个事务的打扰. 持久性(Durability) :强调的事务结束之后,数据就永久的保存的数据库中. 安全性问题 脏读:一个事务,读到了另一个事务未提交数据. 不可重复读 :一个事务,读到了另一个事务的提交数据（update）.导致查询结果不一致. 虚读(幻读) :一个事务,读到了另一个事务的提交数据(insert).导致查询结果不一致 丢失更新:一个事务更新了数据,另一个事务也更新数据,后面的事务覆盖了前一个事务的更新 事务的几种传播特性 PROPAGATION_REQUIRED: 如果存在一个事务，则支持当前事务。如果没有事务则开启,默认 PROPAGATION_SUPPORTS: 如果存在一个事务，则支持当前事务。如果没有事务，则非事务的执行 PROPAGATION_MANDATORY: 如果存在一个事务，则支持当前事务。如果没有一个活动的事务，则抛出异常。 PROPAGATION_REQUIRES_NEW: 总是开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。 PROPAGATION_NOT_SUPPORTED: 总是非事务地执行，并挂起任何存在的事务。 PROPAGATION_NEVER: 总是非事务地执行，如果存在一个活动事务，则抛出异常 PROPAGATION_NESTED：如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务, 则按TransactionDefinition.PROPAGATION_REQUIRED 属性执行 Spring事务的隔离级别 ISOLATION_DEFAULT： 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别.MySQL默认repeatable read,Oracle默认read committed 另外四个与JDBC的隔离级别相对应 ISOLATION_READ_UNCOMMITTED： 这是事务最低的隔离级别，它充许令外一个事务可以看到这个事务未提交的数据。 这种隔离级别会产生脏读，不可重复读和幻像读。 ISOLATION_READ_COMMITTED： 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据 ISOLATION_REPEATABLE_READ： 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。 它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。 除了防止脏读，不可重复读外，还避免了幻像读。 悲观锁\\乐观锁解决丢失更新","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ajavac.com/tags/MySQL/"},{"name":"DataBase","slug":"DataBase","permalink":"https://blog.ajavac.com/tags/DataBase/"},{"name":"Transaction","slug":"Transaction","permalink":"https://blog.ajavac.com/tags/Transaction/"}]},{"title":"《Effective Java》读书笔记——第1章","date":"2017-03-14T08:20:00.000Z","path":"2017/03/14/EffectiveJava/chapter1/","text":"引言有效地使用Java及其基本类库十分重要，尤其是： java.lang java.util java.util.concurrent java.io 编写程序的目标是：清晰、正确、可用、健壮、灵活和可维护 Java语言支持四种类型：接口（interface）、类（class）、数组（array）和基本类型（primitive） 前三种为引用类型（reference type），类实例和数组是对象（object），而基本类型的值则不是对象 类的成员（member）由它的域（field）、方法（method）、成员类（member class）和成员接口（member interface）组成 方法的签名（signature）由它的名称和所有参数类型组成，签名不包括它的返回类型 API（Application Programming Interface）指类、接口、构造器（constructor）、成员和序列化形式（serialized form），通过他们可以访问类、接口或者包 一个包导出的API由该包中的每个公有（public）类或者接口中所有公有的或者受保护的（protected）成员和构造器组成","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Effective_Java","slug":"Effective-Java","permalink":"https://blog.ajavac.com/tags/Effective-Java/"},{"name":"book","slug":"book","permalink":"https://blog.ajavac.com/tags/book/"}]},{"title":"字符编码","date":"2017-01-13T08:27:31.000Z","path":"2017/01/13/Common/character/","text":"编程过程中偶尔会遇到乱码问题,对字符编码进行一定的理解可以加快解决问题的速度. 基本概念 字符集:系统支持的所有抽象字符的集合。 常见字符集：ASCII、ISO-8859-1、GB2312、GBK、GB18030、BIG5、Unicode等。 编码(encoding): 编码是信息从一种形式或格式转换为另一种形式的过程。解码，是编码的逆过程。 字符编码(character encoding): 把字符集中的字符编码为指定集合中某一对象（例如：比特模式、自然数序列、8位元组或者电脉冲），以便文本在计算机中存储和通过通信网络的传递。一般一种字符集对应一种字符编码方式，其中Unicode字符集有多种编码方式，比如UTF-8、UTF-16、UTF-32。不同字符集间转换一般使用Unicode字符集作为中介，先转换为Unicode字符，然后再查码表进行转换。 Unicode Unicode (万国码,国际码,统一码,单一码)是计算机领域的一项业界标准,对世界上大部分文字系统进行整理和编码,使电脑可以用更为简单的方式类呈现和处理文字. Java程序在运行时，内存中的字符使用Unicode字符集，使用UTF-16的编码方式（一般为2个字节，辅助平面字符需要4个字节） Unicode使用16位的编码空间，每个字符占用2个字节(附加字符需要4个字节) 一个字符的Unicode编码是确定的 Unicode的实现方式称为Unicode转换格式（Unicode Transformation Format，简称为UTF）. UTF-8 UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字元编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字元，且其编码中的第一个位元组仍与ASCII相容，这使得原来处理ASCII字元的软体无须或只须做少部份修改，即可继续使用。因此，它逐渐成为电子邮件、网页及其他储存或传送文字的应用中，优先采用的编码。 只包含7位ASCII字符的文件在ASCII和UTF-8两种编码方式下是一樣的 UTF-8是一种变长编码方式(1-4个字节),兼容ASCII 其中英文字符占用1个字节,中文字符占用3个字节,所以相对来说,占用存储空间较少 UTF-16 采用2个字节或者4个字节(辅助平面字符)的编码方式,是Java中字符的编码方式 英文也占用2个字节,所以比较浪费空间 优点是编解码方便,效率高,字符定位容易 缺点是占用空间大,采用顺序编码,若字符损坏无法进行校验 UTF-32 采用4个字节的定长编码方式 英文也占用4个字节 占用空间大 有大小端的区别 Java中的编码 Java程序默认使用UTF-16编码(字符串String的编码) JVM编码:Uninx默认使用UTF-8,Windows默认使用GBK(文件系统编码方式),所以最好指定编码方式,加入JVM参数-Dfile.encoding=utf8 String的getBytes()方法默认使用的是JVM默认的编码方式来编码(不同操作系统可能会不一样,所以最好指定编码方式) String的getBytes(Charset)方法指定编码方式来编码字符串 new String(byte[])方法默认使用的是JVM默认的编码方式来解码(不同操作系统可能会不一样,所以最好指定编码方式) new String(byte[],Charset)方法可以对byte[]进行指定编码方式解码 乱码需要使用当时编码时候用的错误解码方式进行编码后再重新解码 很多框架使用ISO-8859-1编码,存在黑洞问题,容易造成中文丢失,new String(str.getBytes(&quot;utf-8&quot;),&quot;iso-8859-1&quot;);有可能能解决问题 不同编码方式占用字节(byte) 非特殊字符情况下 编码方式 1个英文字符(ASCII) 1个中文字符 GB2312 1 2 GBK 1 2 UTF-8 1 3 UTF-16 2 2 UTF-32 4 4 Unicode 2 2 其中GBK兼容GB2312,可以说GBK是GB2312的超集 参考链接:WIKI_编码 WIKI_字符编码 WIKI_Unicode 字符集和字符编码（Charset &amp; Encoding）","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"Charset","slug":"Charset","permalink":"https://blog.ajavac.com/tags/Charset/"}]},{"title":"MySQL数据类型","date":"2017-01-06T05:53:52.000Z","path":"2017/01/06/MySQL/mysql_data_type/","text":"MySQL 数据类型char与varchar char性能优于varchar（会用1-2个字节存储字符串长度），也不易产生碎片，适合用于存储长度较为固定的字符串 进行字符比较时候默认是不区分大小写的 char(4)可以存4个字符，根据编码方式占据不同的字节（UTF-8每个字符占据3字节） varchar(4)可以存4个字符，根据编码方式以及存放字节长度占据不同的字节（会用1-2个字节存储字符串长度） char和varchar末尾有空格的话，char会自动去掉空格后存储，varchar虽然不会去掉空格，但在进行字符串比较时，会去掉空格进行比较 字符比较区分大小写的方法： select时候加上binary，如：select * from test where name like binary &#39;%王%&#39;; 建表时候或者修改表列数据类型为varchar(32) binary这种格式 binary binary保存二进制字符串，它保存的是字节，没有字符集限制，比较时候比较的是字节，区分大小写，按字节比较比字符简单快速 binary(8)可以保存8个字节的数据，结尾使用\\0填充，而不是空格 Blob与Text BLOB是二进制大对象，容纳可变数量的数据。有4种类型：TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB。可容纳值的最大长度不同。 TEXT类型也有四种：TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT。对应4种BLOB类型，有相同的最大长度和存储需求。 大体上可将BLOB列视为能够足够大的VARBINARY列，将TEXT列视为VARCHAR列。 BLOB和TEXT列不能有 默认值。 由于BLOB和TEXT值可能会非常长，使用它们时可能遇到一些约束： 当排序时只使用该列的前max_sort_length个字节。max_sort_length的 默认值是1024；该值可以在启动mysqld服务器时使用–max_sort_length选项进行更改。 运行时增加max_sort_length的值可以在排序或组合时使更多的字节有意义。任何客户端可以更改其会话max_sort_length变量的值：复制代码 代码如下: mysql&gt; SET max_sort_length = 2000; mysql&gt; SELECT id, comment FROM tbl_name 1-&gt; ORDER BY comment; 当你想要使超过max_sort_length的字节有意义，对含长值的BLOB或TEXT列使用GROUP BY或ORDER BY的另一种方式是将列值转换为固定长度的对象。标准方法是使用SUBSTRING函数。例如，下面的语句对comment列的2000个字节进行排序：复制代码 代码如下: mysql&gt; SELECT id, SUBSTRING(comment,1,2000) FROM tbl_name 1-&gt; ORDER BY SUBSTRING(comment,1,2000); BLOB或TEXT对象的最大大小由其类型确定，但在客户端和服务器之间实际可以传递的最大值由可用内存数量和通信缓存区大小确定。你可以通过更改max_allowed_packet变量的值更改消息缓存区的大小，但必须同时修改服务器和客户端程序。例如，可以使用mysql和mysqldump来更改客户端的max_allowed_packet值。 每个BLOB或TEXT值分别由内部分配的对象表示。这与其它列类型形成对比，后者是当打开表时为每1列分配存储引擎。","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ajavac.com/tags/MySQL/"}]},{"title":"Java Web 项目配置文件提取方案","date":"2016-12-01T07:02:57.000Z","path":"2016/12/01/Java/java_web_config/","text":"Java Web 项目配置文件提取方案 如果使用war包部署项目,配置文件在war包里面会有很多不便,所以考虑将配置文件提取出来,当然,这是针对传统Java Web项目 开发时在开发时候,配置文件使用项目中的配置文件 首先,修改web.xml,添加定制配置文件目录项目中的/WEB-INF/config作为基础配置文件目录 1234&lt;context-param&gt; &lt;param-name&gt;configDir&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/config&lt;/param-value&gt;&lt;/context-param&gt; 在需要导入配置的地方可以用如下方式导入 1&lt;context:property-placeholder location=\"$&#123;configDir&#125;/database.properties\" ignore-unresolvable=\"true\"/&gt; 比如,spring的配置注入 12345678910&lt;bean id=\"configProperties\" class=\"org.springframework.beans.factory.config.PropertiesFactoryBean\"&gt; &lt;property name=\"locations\"&gt; &lt;list&gt; &lt;value&gt;$&#123;configDir&#125;/*.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"propertyConfigurer\" class=\"org.springframework.beans.factory.config.PreferencesPlaceholderConfigurer\"&gt; &lt;property name=\"properties\" ref=\"configProperties\" /&gt;&lt;/bean&gt; 生产环境 生产环境中,使用其他目录作为配置文件目录,已确保更新war包时候不会把原配置替换掉 要自定义配置目录，则可以修改webapp的Context Descriptor。以tomcat为例：在如下目录${CATALINA_HOME}/conf/Catalina/localhost/下建立[webapp_name].xml，这里是registryService.xml，内容如下： 1234&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;Context&gt; &lt;Parameter name=\"configDir\" value=\"file:/app/config\" override=\"false\"/&gt;&lt;/Context&gt; 其中,value=&quot;file:/app/config&quot;表示配置文件都放在/app/config目录下","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.ajavac.com/tags/Java/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://blog.ajavac.com/tags/Tomcat/"}]},{"title":"Nginx入门","date":"2016-11-24T07:34:53.000Z","path":"2016/11/24/Nginx/nginx_guide/","text":"Nginx入门简介Nginx是一个WebServer,它能够反向代理HTTP,HTTPS,SMTP,POP3,IMAP等的协议链接,可以实现负载均衡和HTTP缓存,功能十分强大.Nginx采用异步非阻塞的设计,性能强大,支持高并发,而且占用资源极低. 安装与使用windowscmd切换到nginx目录下 启动:start ngix 停止:nginx -s stop 重新加载:nginx -s reload linuxservice nginx (start|stop|restart) 反向代理反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。 作用: 保护网站安全:所有连接都经过该服务器 通过配置缓存功能加速Web请求 实现负载均衡 高可用/热更新/防盗链等等 配置修改conf/nginx.conf 1234567891011121314151617181920212223242526272829303132worker_processes 2;#worker进程数,一般配置为cpu核数events &#123; worker_connections 1024;#每个worker处理的连接数&#125;http &#123; #服务器集群,命名为tomcats upstream tomcats &#123; server 192.168.68.121:8080;#服务器1,此处可用域名,不带端口则默认80端口 server 192.168.68.121:8081;#服务器2 server 192.168.12.121:8081;#服务器3 &#125; server &#123; listen 80;#nginx监听的端口号 server_name localhost;#服务器域名 #所有的请求转向自定义的tomcats负载均衡服务器列表 location / &#123; proxy_pass http://tomcats;#代理的服务器集群 #proxy_redirect off; #设置请求头 proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 负载均衡规则有: round-robin:循环,默认规则,请求会循环指向服务列表的各个服务器 least-connected :最少连接,请求会指向当前连接数最少的服务器 ip-hash:哈希,会根据请求的客户端ip的哈希值指向服务器列表中的某一个服务器,这样采用session的服务器才能更好地发挥作用,但是并不是很好的实现负载均衡功能 weight:按照权重来指向各个服务器 配置: 123456789101112131415161718192021222324252627# least-connected配置方法upstream myapp1 &#123; least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125;# ip-hash配置方法upstream myapp1 &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125;# 权重配置upstream myapp1 &#123; # 每5个连接会有3个到srv1,1个到srv2,1个到srv3 server srv1.example.com weight=3; server srv2.example.com; server srv3.example.com;&#125;# 健康检查upstream myapp1 &#123; server srv1.example.com;#默认情况下max_fails=1 服务器一次访问失败就会被标记为宕机,不可用,默认10秒访问超时 server srv2.example.com max_fails=3 fail_timeout=20;#3次失败,20秒访问超时 server srv3.example.com max_fails=0;#不论几次失败都可用&#125; location规则语法规则： location [=|~|~*|^~] /uri/ { … } = 开头 表示精确匹配 ^~ 开头 表示uri以某个常规字符串开头(支持正则)。nginx不对url做编码 ~ 开头 表示区分大小写的正则匹配 ~* 开头 表示不区分大小写的正则匹配 !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则 / 通用匹配，任何请求都会匹配到 匹配顺序:首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。同等级匹配多个则选择较长的匹配","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.ajavac.com/tags/Nginx/"}]},{"title":"证书相关知识","date":"2016-11-24T07:32:53.000Z","path":"2016/11/24/Common/certificate/","text":"证书相关知识加密算法对称密钥加密 加/解密一般使用同一个密钥或者可互相推算的密钥,通常称之为”Session Key”,计算速度较快. 常见的对称加密算法有DES、3DES、AES、Blowfish、IDEA、RC5、RC6。 非对称密钥加密 加/解密使用不同的密钥,通常有两个密钥,成为”公钥”和”私钥”,需要配对使用.公钥加密的数据只有私钥可以解开,私钥加密的数据只有公钥才能解开.一般公钥是公开的,可被人知道,私钥需要妥善保存.计算速度慢. 常见的公钥加密算法有：RSA、ElGamal、背包算法、Rabin（RSA的特例）等。 使用最广泛的是RSA算法。 摘要算法 散列函数（或散列算法，又称哈希函数，英语：Hash Function）是一种从任何一种数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。好的散列函数在输入域中很少出现散列冲突。 常见摘要算法: MD5、SHA1、SHA256、SHA512 特点: 摘要信息压缩了输入信息 摘要结果不可逆 源信息被修改则摘要结果改变(雪崩效应) 一般来说,摘要结果不同,说明输入信息不同 常用来保证数据的完整性 数字证书 是一种用于电脑的身份识别机制,一般由权威的值得信赖的第三方机构(一般是由政府审核并授权的机构)来统一对外发放,也成为CA证书 比较常见的还有国际权威的数字证书认证机构，比如 GlobalSign、VeriSign、GeoTrust、Comodo， 一般收取高额费用。也有免费的数字证书认证机构，比如CAcert和 StartSSL。 所以自签证书是个掩耳盗铃的事情 证书颁发过程 用户首先产生自己的密钥对，并将公共密钥及部分个人身份信息传送给认证中心。认证中心在核实身份后，将执行一些必要的步骤，以确信请求确实由用户发送而来，然后，认证中心将发给用户一个数字证书，该证书内包含用户的个人信息和他的公钥信息，同时还附有认证中心的签名信息(根证书私钥签名)。用户就可以使用自己的数字证书进行相关的各种活动。数字证书由独立的证书发行机构发布，数字证书各不相同，每种证书可提供不同级别的可信度。 证书内容 证书颁发机构的名称 证书本身的数字签名 证书持有者公钥 证书签名用到的Hash算法 证书有效性验证浏览器默认都会内置CA根证书，其中根证书包含了CA的公钥 证书的签发是一级一级往下签发,还有一个CRL列表(吊销列表) 证书颁发的机构是伪造的：浏览器不认识，直接认为是危险证书 证书颁发的机构是确实存在的，于是根据CA名，找到对应内置的CA根证书、CA的公钥。用CA的公钥，对伪造的证书的摘要进行解密，发现解不了，认为是危险证书。 对于篡改的证书，使用CA的公钥对数字签名进行解密得到摘要A，然后再根据签名的Hash算法计算出证书的摘要B，对比A与B，若相等则正常，若不相等则是被篡改过的。 证书可在其过期前被吊销，通常情况是该证书的私钥已经失密。较新的浏览器如Chrome、Firefox、Opera和Internet Explorer都实现了在线证书状态协议（OCSP）以排除这种情形：浏览器将网站提供的证书的序列号通过OCSP发送给证书颁发机构，后者会告诉浏览器证书是否还是有效的。 1、2点是对伪造证书进行的，3是对于篡改后的证书验证，4是对于过期失效的验证。 HTTPsHTTPS和HTTP的区别 HTTP默认使用80端口，HTTPS默认使用443端口 HTTPS协议需要CA证书 HTTP是超文本传输协议，信息是明文传输；HTTPsS则是具有安全性的SSL/TLS加密传输协议 HTTP和HTTPS使用的是完全不同的连接方式 HTTP的连接很简单，是无状态的 HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP协议安全 HTTP协议相对简单,所以传输速度较HTTPS快,但是现在差别已经不是很大. HTTPS部署相对复杂 SSL 与 TLSSSL(Secure Socket Layer)安全套接字层 SSL为Netscape所研发，用以保障在Internet上数据传输之安全，利用数据加密(Encryption)技术，可确保数据在网络上之传输过程中不会被截取，当前为3.0版本。 SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。 TLS (Transport Layer Security，传输层安全协议)用于两个应用程序之间提供保密性和数据完整性。TLS 1.0是IETF（Internet Engineering Task Force，Internet工程任务组）制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本，可以理解为SSL 3.1，它是写入了 RFC 的。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。较低的层为 TLS 记录协议，位于某个可靠的传输协议（例如 TCP）上面。 SSL/TLS协议作用： 认证用户和服务器，确保数据发送到正确的客户机和服务器； 加密数据以防止数据中途被窃取； 维护数据的完整性，确保数据在传输过程中不被改变。 TLS比SSL的优势 对于消息认证使用密钥散列法：TLS 使用“消息认证代码的密钥散列法”（HMAC），当记录在开放的网络（如因特网）上传送时，该代码确保记录不会被变更。SSLv3.0还提供键控消息认证，但HMAC比SSLv3.0使用的（消息认证代码）MAC 功能更安全。 增强的伪随机功能（PRF）：PRF生成密钥数据。在TLS中，HMAC定义PRF。PRF使用两种散列算法保证其安全性。如果任一算法暴露了，只要第二种算法未暴露，则数据仍然是安全的。 改进的已完成消息验证：TLS和SSLv3.0都对两个端点提供已完成的消息，该消息认证交换的消息没有被变更。然而，TLS将此已完成消息基于PRF和HMAC值之上，这也比SSLv3.0更安全。 一致证书处理：与SSLv3.0不同，TLS试图指定必须在TLS之间实现交换的证书类型。 特定警报消息：TLS提供更多的特定和附加警报，以指示任一会话端点检测到的问题。TLS还对何时应该发送某些警报进行记录。 https实际就是在TCP层与http层之间加入了SSL/TLS来为上层的安全保驾护航，主要用到对称加密、非对称加密、证书，等技术进行客户端与服务器的数据加密传输，最终达到保证整个通信的安全性。 session的恢复session IDsession ID的思想很简单，就是每一次对话都有一个编号（session ID）。如果对话中断，下次重连的时候，只要客户端给出这个编号，且服务器有这个编号的记录，双方就可以重新使用已有的”对话密钥”，而不必重新生成一把。 session ID是目前所有浏览器都支持的方法，但是它的缺点在于session ID往往只保留在一台服务器上。所以，如果客户端的请求发到另一台服务器，就无法恢复对话 session ticket客户端发送一个服务器在上一次对话中发送过来的session ticket。这个session ticket是加密的，只有服务器才能解密，其中包括本次对话的主要信息，比如对话密钥和加密方法。当服务器收到session ticket以后，解密后就不必重新生成对话密钥了。 目前只有Firefox和Chrome浏览器支持。 可信时间戳 可信时间戳是由权威可信时间戳服务中心签发的一个能证明数据电文(电子文件）在一个时间点是已经存在的、完整的、可验证的，具备法律效力的电子凭证，可信时间戳主要用于电子文件防篡改和事后抵赖，确定电子文件产生的准确时间。 PKI The PKI role that assures valid and correct registration is called a registration authority (RA). An RA is responsible for accepting requests for digital certificates and authenticating the entity making the request.In a Microsoft PKI, a registration authority is usually called a subordinate CA. An entity must be uniquely identifiable within each CA domain on the basis of information about that entity. A third-party validation authority (VA) can provide this entity information on behalf of the CA. 概念: CA 数字证书认证机构(Certificate Authority) RA 审核注册管理机构(Registration Authority) VA 有效性认证机构(Validation Authority ) PKI是“Public Key Infrastructure”的缩写，意为“公钥基础设施”。简单地说，PKI技术就是利用公钥理论和技术建立的提供信息安全服务的基础设施。公钥体制是目前应用最广泛的一种加密体制，在这一体制中，加密密钥与解密密钥各不相同，发送信息的人利用接收者的公钥发送加密信息，接收者再利用自己专有的私钥进行解密。这种方式既保证了信息的机密性，又能保证信息具有不可抵赖性。目前，公钥体制广泛地用于CA认证、数字签名和密钥交换等领域。PKI可以作为支持认证、完整性、机密性和不可否认性的技术基础，从技术上解决网上身份认证、信息完整性和抗抵赖等安全问题，为网络应用提供可靠的安全保障。 参考文献: 1.對稱密鑰加密 2.公开密钥加密 3.散列函數 4.電子證書 5.Public_key_infrastructure 6.详解https是如何确保安全的 7.图解SSL/TLS协议 8.可信时间戳 9.公钥基础设施 PKI 技术与应用发展","tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://blog.ajavac.com/tags/HTTPS/"},{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"}]},{"title":"Git基础","date":"2016-07-22T01:48:22.000Z","path":"2016/07/22/Common/git_primer/","text":"参考链接:廖雪峰的官方网站 Quick Learn Git !快捷键mkdir &lt;dirname&gt; 创建文件夹 cd &lt;dirname&gt;目录移动 pwd 显示当前目录 git init 把当前目录变成Git可以管理的仓库 ls -ah 显示所有文件，包括隐藏 git add &lt;file1 file2&gt; 添加文件到仓库 git commit -m &quot;description...&quot; 提交变更 git status 查看git状态 git diff &lt;file&gt; 查看file的修改情况 git log 查看git历史记录 git log -pretty=oneline 单行查看git历史记录 git reset --hard HEAD^ git回上一个版本 cat &lt;file&gt; 查看file的内容 git reset --hard 363824 版本回到commit id为363824的版本 git reflog 查看所有的历史git版本 git diff HEAD -- &lt;file&gt; 查看工作区和版本库最新版本区别 git checkout -- &lt;file&gt; 丢弃工作区的修改并回到版本库最新版本(stage和库取最新) git reset HEAD &lt;file&gt; 撤销掉stage版本（unstage） git rm &lt;file&gt; 从版本库删除文件 git工作区、暂存区概念 GItHub 设置ssh-keygen -t rsa -C &quot;wyp0596@qq.com&quot; 一路回车 上GitHub添加Key GitHubgit remote add origin git@github.com:wyp0596/learngit.git 关联 git push -u origin master 推送。。第一次推送用－u 以后不需要 git clone git@github.com:wyp0596/learngit.git 克隆 分支管理git checkout -b dev 创建dev分支并切换分支 相当于 1234$ git branch dev$ git checkout dev git branch 查看当前分支 git checkout master 切换回master分支 git merge dev 把dev分支合并到master分支上 git branch -d dev 删除dev分支 git log --graph --pretty=oneline --abbrev-commit 查看分支的合并情况 git merge --no-ff -m &quot;merge with no-ff&quot; dev 不使用ff模式合并分支dev 保存、恢复现场git stash 保存现场 git stash list 现场列表 git stash pop 恢复现场，并删除存档（多现场要指定现场stash@{1}） git stash apply 恢复现场 git stash drop 删除存档 多人协作 首先，可以试图用git push origin branch-name推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功！ 如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream branch-name origin/branch-name。 这就是多人协作的工作模式，一旦熟悉了，就非常简单。 查看远程库信息，使用git remote -v； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 标签git tag 标签列表 git tag v1.0 添加标签v1.0到当前commit git log --pretty=oneline --abbrev-commit 查看commmit git tag v0.9 622333 添加标签v1.0到指定commit git show v0.9 $ git tag -a v0.1 -m &quot;version 0.1 released&quot; 3628164 带说明的标签 $ git tag -s v0.2 -m &quot;signed version 0.2 released&quot; fec145a 用私钥签名一个标签 git tag -d v0.1 删除本地标签 git push origin v1.0 上传标签 git push origin --tags 推送所有未推送标签 git push origin :refs/tags/v0.9 删除远程标签 自定义Gitgit config --global color.ui true 加上颜色 .gitignore 偷懒流 1234567891011121314$ git config --global alias.st status$ git config --global alias.co checkout$ git config --global alias.ci commit$ git config --global alias.br branch$ git config --global alias.unstage &apos;reset HEAD&apos;$ git config --global alias.last &apos;log -1&apos;$ git config --global alias.lg &quot;log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit&quot;","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"Git","slug":"Git","permalink":"https://blog.ajavac.com/tags/Git/"}]},{"title":"MySQL基本操作","date":"2016-07-14T07:48:22.000Z","path":"2016/07/14/MySQL/mysql_basic/","text":"参考自:http://wiki.jikexueyuan.com/project/mysql-21-minutes/ 导入数据库从sql脚本导入 首先建空数据库mysql&gt;create database abc; 导入数据库方法一：（1）选择数据库mysql&gt;use abc;（2）设置数据库编码mysql&gt;set names utf8;（3）导入数据（注意sql文件的路径）mysql&gt;source /home/abc/abc.sql;方法二：mysql -u用户名 -p 数据库名 &lt; 数据库名.sqlmysql -uabc_f -p abc &lt; abc.sql 从excel等导入 另存为csv用，分割 load data local infile &#39;C:\\\\abc.txt&#39; into table t fields terminated by &#39;,&#39;; 导出数据库用mysqldump命令（注意MySQL的安装路径，即此命令的路径）：1、导出数据和表结构：mysqldump -u用户名 -p 数据库名 &gt; 数据库名.sql/usr/local/mysql/bin/mysqldump -uroot -p abc &gt; abc.sql敲回车后会提示输入密码 2、只导出表结构mysqldump -u用户名 -p -d 数据库名 &gt; 数据库名.sql/usr/local/mysql/bin/mysqldump -uroot -p -d abc &gt; abc.sql 创建数据库使用 create database 语句可完成对数据库的创建, 创建命令的格式如下: create database 数据库名 [其他选项];例如我们需要创建一个名为 samp 的数据库, 在命令行下执行以下命令: create database samp;提示: 可以使用 show databases; 命令查看已经创建了哪些数据库。 use 语句可以不加分号, 执行 use samp 来选择刚刚创建的数据库, 选择成功后会提示: Database changed 创建数据库表使用 create table 语句可完成对表的创建, create table 的常见形式: create table 表名称(列声明); 以创建 students 表为例, 表中将存放 学号(id)、姓名(name)、性别(sex)、年龄(age)、联系电话(tel) 这些内容:12345678create table students（ id int unsigned not null auto_increment primary key, name char(8) not null, sex char(4) not null, age tinyint unsigned not null, tel char(13) null default &quot;-&quot;); 操作 MySQL 数据库向表中插入数据insert 语句可以用来将一行或多行数据插到数据库表中, 使用的一般形式如下: insert [into] 表名 [(列名1, 列名2, 列名3, ...)] values (值1, 值2, 值3, ...);其中 [] 内的内容是可选的, 例如, 要给 samp_db 数据库中的 students 表插入一条记录, 执行语句: insert into students values(NULL, &quot;王刚&quot;, &quot;男&quot;, 20, &quot;13811371377&quot;); 有时我们只需要插入部分数据, 或者不按照列的顺序进行插入, 可以使用这样的形式进行插入: insert into students (name, sex, age) values(&quot;孙丽华&quot;, &quot;女&quot;, 21); 查询表中的数据select 语句常用来根据一定的查询规则到数据库中获取数据, 其基本的用法为: select 列名称 from 表名称 [查询条件];例如要查询 students 表中所有学生的名字和年龄, 输入语句 select name, age from students; 也可以使用通配符 查询表中所有的内容, 语句: select * from students; 按特定条件查询where 关键词用于指定查询条件, 用法形式为: select 列名称 from 表名称 where 条件; 以查询所有性别为女的信息为例, 输入查询语句: select * from students where sex=&quot;女&quot;; where 子句不仅仅支持 “where 列名 = 值” 这种名等于值的查询形式, 对一般的比较运算的运算符都是支持的, 例如 =、&gt;、&lt;、&gt;=、&lt;、!= 以及一些扩展运算符 is [not] null、in、like 等等。 还可以对查询条件使用 or 和 and 进行组合查询, 以后还会学到更加高级的条件查询方式, 这里不再多做介绍。 示例: 查询年龄在 21 岁以上的所有人信息: select * from students where age &gt; 21; 查询名字中带有 “王” 字的所有人信息: select * from students where name like &quot;%王%&quot;; 查询 id 小于 5 且年龄大于 20 的所有人信息: select * from students where id&lt;5 and age&gt;20; 更新表中的数据update 语句可用来修改表中的数据, 基本的使用形式为: update 表名称 set 列名称=新值 where 更新条件; 使用示例: 将 id 为 5 的手机号改为默认的”-“:update students set tel=default where id=5; 将所有人的年龄增加 1: update students set age=age+1; 将手机号为 13288097888 的姓名改为 “张伟鹏”, 年龄改为 19:update students set name=&quot;张伟鹏&quot;, age=19 where tel=&quot;13288097888&quot;; 删除表中的数据delete 语句用于删除表中的数据, 基本用法为: delete from 表名称 where 删除条件; 使用示例: 删除 id 为 2 的行: delete from students where id=2; 删除所有年龄小于 21 岁的数据: delete from students where age&lt;20; 删除表中的所有数据: delete from students; 创建后表的修改alter table 语句用于创建后对表的修改, 基础用法如下: 添加列基本形式: alter table 表名 add 列名 列数据类型 [after 插入位置]; 示例: 在表的最后追加列 address: alter table students add address char(60); 在名为 age 的列后插入列 birthday: alter table students add birthday date after age; 修改列基本形式: alter table 表名 change 列名称 列新名称 新数据类型; 示例: 将表 tel 列改名为 telphone: alter table students change tel telphone char(13) default &quot;-&quot;; 将 name 列的数据类型改为 char(16): alter table students change name name char(16) not null; 删除列基本形式: alter table 表名 drop 列名称; 示例: 删除 birthday 列: alter table students drop birthday; 重命名表基本形式: alter table 表名 rename 新表名; 示例: 重命名 students 表为 workmates: alter table students rename workmates; 删除整张表基本形式: drop table 表名; 示例: 删除 workmates 表: drop table workmates; 删除整个数据库基本形式: drop database 数据库名; 示例: 删除 samp_db 数据库: drop database samp_db;","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ajavac.com/tags/MySQL/"}]},{"title":"MySQL安装和配置","date":"2016-07-14T03:12:22.000Z","path":"2016/07/14/MySQL/mysql_install/","text":"安装MySQLDocker安装 mysql官方镜像 12345678910#1.最基础的运行方式,容器名为some-mysql,密码为admindocker run --name some-mysql -e MYSQL_ROOT_PASSWORD=admin -d mysql#2.持久化文件保存到外部磁盘/docker/host/dirdocker run --name some-mysql -v /docker/host/dir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=admin -d mysql#3.宿主-容器端口映射3306:3306docker run --name some-mysql -v /docker/host/dir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=admin -d -p 3306:3306 mysql#4.其他容器连接mysqldocker run --name some-app --link some-mysql:mysql -d application-that-uses-mysql#5.mysql命令行测试连接docker run -it --link some-mysql:mysql --rm mysql sh -c 'exec mysql -h\"$MYSQL_PORT_3306_TCP_ADDR\" -P\"$MYSQL_PORT_3306_TCP_PORT\" -uroot -p\"$MYSQL_ENV_MYSQL_ROOT_PASSWORD\"' Ubuntuubuntu上安装mysql非常简单只需要几条命令就可以完成。 sudo apt-get install mysql-server sudo apt-get install mysql-client sudo apt-get install libmysqlclient-dev安装过程中会提示设置密码什么的，注意设置了不要忘了，安装完成之后可以使用如下命令来检查是否安装成功：sudo netstat -tap | grep mysql 通过上述命令检查之后，如果看到有mysql 的socket处于 listen 状态则表示安装成功。 登陆mysql数据库可以通过如下命令：mysql -u root -p此时输入密码就可以登录到mysql Mac安装 HomeBrew安装 官网安装 略 Win安装 绿色安装 按需修改my.ini(复制my-default.ini并改名为my.ini) mysql的bin目录下执行mysqld --initialize-insecure来初始化mysql mysqld —install安装MySQL服务 net start mysql启动mysql服务 mysql -uroot免密码登录mysql mysql&gt;alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;password&#39;;修改root的密码 官网安装 配置MySQL添加远程用户 mysql&gt;GRANT ALL PRIVILEGES ON *.* TO username@&quot;%&quot; IDENTIFIED BY &#39;password&#39; WITH GRANT OPTION;添加一个用户username/密码为password, 并授权可以从其他任何主机发起访问。 mysql&gt;flush privileges; 刷新刚才的内容 ​ 数据库编码格式修改在Mac或Linux下，需要编辑MySQL的配置文件，把数据库默认的编码全部改为UTF-8。Linux下MySQL的配置文件默认存放在/etc/my.cnf或者/etc/mysql/my.cnfMac下MySQL的配置文件默认存放在/usr/local/mysql/support-files/sudo cp my-default.cnf /etc/my.cnfsudo vim my.cnf 1234567891011121314151617[mysql]default-character-set=utf8[mysqld]port = 3306max_connections=200character-set-server=utf8default-storage-engine=INNODBsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLESkey_buffer_size = 256Mmax_allowed_packet = 1Mtable_open_cache = 256sort_buffer_size = 1Mread_buffer_size = 1Mread_rnd_buffer_size = 4Mmyisam_sort_buffer_size = 64Mthread_cache_size = 8Mquery_cache_size = 16M 重启MySQL后，可以通过MySQL的客户端命令行检查编码：show variables like &#39;%char%&#39;; 123456789101112mysql&gt; show variables like &apos;%char%&apos;; +--------------------------+--------------------------------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/local/mysql-5.1.65-osx10.6-x86_64/share/charsets/ |+--------------------------+--------------------------------------------------------+8 rows in set (0.00 sec) 看到utf8字样就表示编码设置正确。 精简MySQL精简方法如下： 删除docs，include，lib，mysql-test，scripts，sql-bench目录，只保留bin，data和share目录。 删除bin目录里后缀名为.pdb的文件(调试文件)。 如果还想精简，那再继续下一步。 删除bin目录下除mysqladmin.exe，mysqld.exe，mysql.exe以外的所有文件。 还可以删除data目录下的ib_logfile0，ib_logfile1，ibdata1以及后缀名为err和pid的Log文件。","tags":[{"name":"Common","slug":"Common","permalink":"https://blog.ajavac.com/tags/Common/"},{"name":"MySQL","slug":"MySQL","permalink":"https://blog.ajavac.com/tags/MySQL/"}]}]